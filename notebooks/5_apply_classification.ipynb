{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Photometric Classification To Fit Results\n",
    "\n",
    "This notebook applies the photometric classification method from González-Gaitán et al. 2014 to SDSS, DES, and CSP light-curve fits. Results are then used to analyze the properties of peculiar supernovae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sncosmo\n",
    "from astropy.table import Table\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.plotting import figure\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.utils import resample\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from analysis_pipeline.data_access import csp\n",
    "from analysis_pipeline import SN91bgSource, get_fit_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We begin by reading in SNCosmo fit results for SDSS, DES, and CSP. This includes fits that use all observed bands, along with those that exclusively use the restframe blue and restframe red filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "salt_2_4 = sncosmo.Model(source=sncosmo.get_source('salt2', version='2.4'))\n",
    "sn_91bg = sncosmo.Model(source=SN91bgSource())\n",
    "\n",
    "for survey in ('csp', 'des', 'sdss'):\n",
    "    for model in (salt_2_4, sn_91bg):\n",
    "        for param_num in (4, 5):\n",
    "            var_pattern = f'{survey}_{model.source.name}_{param_num}p_{{}}'\n",
    "            all_bands, blue, red = get_fit_results(survey, model, param_num)\n",
    "            \n",
    "            for var, string in [(all_bands, 'all'), (blue, 'blue'), (red, 'red')]:\n",
    "                if var is None:\n",
    "                    msg = 'Could not find {} param fit in {} bands for {} - {}'\n",
    "                    print(msg.format(param_num, string, survey, model.source.name))\n",
    "                \n",
    "                else:\n",
    "                    globals()[var_pattern.format(string)] = var\n",
    "\n",
    "csp_sn91bg_4p_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the difference in normalized chi-squared values between the Ia and 91bg models. In algebraic form, this is to say we calculate the following:\n",
    "\n",
    "$$\\chi^2_{blue, \\, red}(Ia) - \\chi^2_{blue, \\, red}(91bg)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_chisquared_diff(snia_blue, snia_red, bg_blue, bg_red):\n",
    "    \"\"\"Calculate the difference between the normalized chi-squared\n",
    "    of the Salt and 91bg model in restframe blue and red bands\n",
    "\n",
    "    Args:\n",
    "        snia_blue (DataFrame): Salt fit results in the resftram blue\n",
    "        snia_red  (DataFrame): Salt fit results in the resftram red\n",
    "        bg_blue   (DataFrame): 91bg fit results in the resftram blue\n",
    "        bg_red    (DataFrame): 91bg fit results in the resftram red\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame with columns 'red' and 'blue'\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_snia = snia_blue.join(snia_red, lsuffix='_blue', rsuffix='_red')\n",
    "    combined_snia['chi_norm_blue'] = combined_snia['chi_blue'] / combined_snia['dof_blue']\n",
    "    combined_snia['chi_norm_red'] = combined_snia['chi_red'] / combined_snia['dof_red']\n",
    "    \n",
    "    combined_91bg = bg_blue.join(bg_red, lsuffix='_blue', rsuffix='_red')\n",
    "    combined_91bg['chi_norm_blue'] = combined_91bg['chi_blue'] / combined_91bg['dof_blue']\n",
    "    combined_91bg['chi_norm_red'] = combined_91bg['chi_red'] / combined_91bg['dof_red']\n",
    "    \n",
    "    # Calculate chi-squared differences\n",
    "    chi_squared_values = pd.DataFrame({\n",
    "        'blue': combined_snia['chi_norm_blue'] - combined_91bg['chi_norm_blue'],\n",
    "        'red': combined_snia['chi_norm_red'] - combined_91bg['chi_norm_red']\n",
    "    })\n",
    "    \n",
    "    return chi_squared_values\n",
    "\n",
    "\n",
    "csp_chi_diff = calc_chisquared_diff(csp_salt2_4p_blue, csp_salt2_4p_red, csp_sn91bg_4p_blue, csp_sn91bg_4p_blue)\n",
    "\n",
    "csp_chi_diff.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the above DataFrame. Note that we draw dashed lines intersecting at (0, 0) for visual reference only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(csp_chi_diff['blue'], csp_chi_diff['red'], label='CSP')\n",
    "\n",
    "plt.axhline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.axvline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "plt.ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize FOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a figure of merit (FOM) value as an optimization parameter for training our classification. The FOM is defined as:\n",
    "\n",
    "$$FOM = \\frac{N_{true}}{N_{tot}} * \\frac{N_{true}}{N_{true} + N_{false}}$$\n",
    "\n",
    "where $N_{true}$ is the number of correctly identified objects of a given type (e.g. 91bg-like objects), $N_{tot}$ is the total input number of that type and $N_{false}$ is the number of objects. In order to calculate this parameter, we will need to construct a DataFrame containing the known classifications of spectroscopically observed targets along with the chi-squared differences from above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csp_spec_class = csp.master_table['SN', 'Subtype1']\n",
    "csp_spec_class.rename_column('Subtype1', 'type')\n",
    "csp_spec_class.rename_column('SN', 'cid')\n",
    "#csp_spec_class = csp_spec_class[~csp_spec_class['type'].mask]\n",
    "\n",
    "classification_data = csp_spec_class.to_pandas()\n",
    "classification_data = classification_data.set_index('cid')\n",
    "classification_data = csp_chi_diff.join(classification_data)\n",
    "classification_data.replace('---      ', 'Unknown', inplace=True)\n",
    "\n",
    "print('Summary of types')\n",
    "classification_data.groupby('type')['red'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a few functions to determine the optimal chi-squared boundaries based on the FOM. We include functions for two types of classification boundaries. The first calculates the FOM using a verticle and horizontal boundary. The second uses a single boundary at an angle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rect_fom(dataframe, blue_cutoff, red_cutoff):\n",
    "    \"\"\"Calculate the rectangular figure of merrit for a set of classifications\n",
    "    \n",
    "    args:\n",
    "        dataframe   (float): \n",
    "        blue_cutoff (float): \n",
    "        red_cutoff  (float): \n",
    "        \n",
    "    Returns:\n",
    "        The figure of merit value\n",
    "    \"\"\"\n",
    "\n",
    "    is_91bg_true = dataframe['type'] == '91bg-like'\n",
    "    is_91bg_classified = (\n",
    "            (dataframe['blue'] > blue_cutoff)\n",
    "            & (dataframe['red'] > red_cutoff)\n",
    "    )\n",
    "\n",
    "    num_tot = sum(is_91bg_true)  # How to handle multiple types?\n",
    "    num_true = sum(is_91bg_true == is_91bg_classified)\n",
    "    num_false = len(dataframe) - num_true\n",
    "    return (num_true / num_tot) * (num_true / (num_true + num_false))\n",
    "\n",
    "\n",
    "def calc_diagonal_fom(dataframe, m, b):\n",
    "    \"\"\"Calculate the rectangular figure of merrit for a set of classifications\n",
    "    \n",
    "    args:\n",
    "        dataframe   (float): \n",
    "        blue_cutoff (float): \n",
    "        red_cutoff  (float): \n",
    "        \n",
    "    Returns:\n",
    "        The figure of merit value\n",
    "    \"\"\"\n",
    "\n",
    "    is_91bg_true = dataframe['type'] == '91bg-like'\n",
    "    is_91bg_predict = m * dataframe['blue'] + b\n",
    "    is_91bg_classified = dataframe['red'] >= is_91bg_predict\n",
    "\n",
    "    num_tot = sum(is_91bg_true)  # How to handle multiple types?\n",
    "    num_true = sum(is_91bg_true == is_91bg_classified)\n",
    "    num_false = len(dataframe) - num_true\n",
    "    return (num_true / num_tot) * (num_true / (num_true + num_false))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Rectangular FOM:')\n",
    "initial_fom = calc_rect_fom(classification_data, 0, 0)\n",
    "print(f'FOM at (0, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda args: 1 / calc_rect_fom(classification_data, *args)\n",
    "rect_result = optimize.minimize(inverse_fom, [.1, 0])\n",
    "rect_result['fun'] = 1 / rect_result['fun']\n",
    "print('Optimization results:')\n",
    "print(rect_result)\n",
    "\n",
    "print('\\n\\nAngled FOM:')\n",
    "initial_fom = calc_diagonal_fom(classification_data, -1, 0)\n",
    "print(f'FOM at (-1, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda args: 1 / calc_diagonal_fom(classification_data, *args)\n",
    "angl_result = optimize.minimize(inverse_fom, [-1, 0])\n",
    "angl_result['fun'] = 1 / angl_result['fun']\n",
    "print('Optimization results:')\n",
    "print(angl_result)\n",
    "\n",
    "print('\\n\\nAngled FOM at 45 degrees:')\n",
    "initial_fom = calc_diagonal_fom(classification_data, -1, 0)\n",
    "print(f'FOM at (-1, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda b: 1 / calc_diagonal_fom(classification_data, -1, b)\n",
    "angl_45_result = optimize.minimize(inverse_fom, 0)\n",
    "angl_45_result['fun'] = 1 / angl_45_result['fun']\n",
    "print('Optimization results:')\n",
    "print(angl_45_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = max(np.abs(classification_data['blue']))\n",
    "line_points = np.array([-a, a])\n",
    "\n",
    "for sn_type in set(classification_data['type']):\n",
    "    i = classification_data['type'] == sn_type\n",
    "    plt.scatter(classification_data['blue'].loc[i], \n",
    "                classification_data['red'].loc[i], \n",
    "                label=sn_type)\n",
    "\n",
    "plt.axvline(rect_result.x[0], linestyle='--', color='black', alpha=.6)\n",
    "plt.axhline(rect_result.x[1], linestyle='--', color='black', alpha=.6)\n",
    "\n",
    "# Rectangular FOM\n",
    "plt.axvline(rect_result.x[0], linestyle='--', color='red', alpha=.6)\n",
    "plt.axhline(rect_result.x[1], linestyle='--', color='red', alpha=.6,\n",
    "            label=f'FOM = {rect_result.fun:.4f}')\n",
    "\n",
    "# Angled FOM\n",
    "angl_line = angl_result.x[0] * line_points + angl_result.x[1]\n",
    "plt.plot(line_points, angl_line, linestyle='-', color='orange', alpha=.6,\n",
    "        label=f'FOM = {angl_result.fun:.4f}')\n",
    "\n",
    "# Angled FOM at 45 degrees\n",
    "angl_45_line = -line_points + angl_result.x[0]\n",
    "plt.plot(line_points, angl_45_line, linestyle='-.', color='green', alpha=.6,\n",
    "         label=f'FOM = {angl_45_result.fun:.4f}')\n",
    "\n",
    "plt.xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "plt.ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a figure of merit optimization, we can bootstrap our data to determine our final classification parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure bootstrap\n",
    "n_iterations = 1000\n",
    "n_size = int(len(classification_data) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "fom_values = []\n",
    "classification_params = []\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    sample_data = resample(classification_data, n_samples=n_size)\n",
    "    inverse_fom = lambda args: 1 / calc_rect_fom(classification_data, *args)\n",
    "    result = optimize.minimize(inverse_fom, [0, 0])\n",
    "\n",
    "    fom_values.append(1 / result.fun)\n",
    "    classification_params.append(result.x)\n",
    "\n",
    "classification_params = np.array(classification_params).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confidence_intervals(alpha, stats):\n",
    "    p = ((1 - alpha) / 2) * 100\n",
    "    lower = max(0, np.percentile(stats, p))\n",
    "\n",
    "    p = (alpha + ((1 - alpha) / 2)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "alpha=0.95\n",
    "confidence = 0.95\n",
    "average_fom = np.average(fom_values)\n",
    "fom_interval = calc_confidence_intervals(confidence, fom_values)\n",
    "\n",
    "print(f'Average FOM: {average_fom}')\n",
    "print(f'{alpha * 100:.1f} confidence interval: [{fom_interval[0] * 100:.1f} '\n",
    "      f', {fom_interval[1] * 100:.1f}]')\n",
    "\n",
    "average_params = np.average(classification_params, axis=1)\n",
    "blue_param_interval = calc_confidence_intervals(confidence, classification_params[0])\n",
    "red_param_interval = np.average(classification_params[1])\n",
    "\n",
    "print(f'Average classification params: {average_params}')\n",
    "print(f'{alpha * 100:.1f} confidence interval for blue '\n",
    "      f'param: [{blue_param_interval[0] * 100:.1f} '\n",
    "      f', {blue_param_interval[1] * 100:.1f}]')\n",
    "\n",
    "print(f'{alpha * 100:.1f} confidence interval for red '\n",
    "      f'param: [{red_param_interval[0] * 100:.1f} '\n",
    "      f', {red_param_interval[1] * 100:.1f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sdss_chi_diff['blue'], sdss_chi_diff['red'], label='SDSS')\n",
    "plt.scatter(des_chi_diff['blue'], des_chi_diff['red'], label='DES')\n",
    "plt.scatter(csp_chi_diff['blue'], csp_chi_diff['red'], label='CSP')\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.axhline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.axvline(average_params[0], linestyle='--', color='red', alpha=.6)\n",
    "plt.axhline(average_params[1], linestyle='--', color='red', alpha=.6,\n",
    "            label=f'FOM = {1 / result.fun}')\n",
    "\n",
    "plt.xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "plt.ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sdss_class] *",
   "language": "python",
   "name": "conda-env-sdss_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
