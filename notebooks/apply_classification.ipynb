{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Photometric Classification To Fit Results\n",
    "\n",
    "This notebook applies the photometric classification method from González-Gaitán et al. 2014 to SDSS, DES, and CSP light-curve fits. Results are then used to analyze the properties of peculiar supernovae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.utils import resample\n",
    "from sndata.csp import dr1\n",
    "from sndata.sdss import sako18\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from phot_class import fom\n",
    "\n",
    "output_notebook()\n",
    "dr1.download_module_data()\n",
    "\n",
    "# Output directory for figures\n",
    "fig_dir = Path('./notebook_figs')\n",
    "fig_dir.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We begin by reading in spectroscopic classificaions for supernovae observed by CSP DR1. We join these classifications with our own classification parameters and perform some book-keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in published CSP DR1 classifications\n",
    "dr1_table_1 = dr1.load_table(1)['SN', 'Type']\n",
    "csp_spec_class = pd.DataFrame({\n",
    "    'obj_id': dr1_table_1['SN'],\n",
    "    'spec_class': dr1_table_1['Type']\n",
    "})\n",
    "csp_spec_class.set_index('obj_id', inplace=True)\n",
    "csp_spec_class.spec_class = csp_spec_class.spec_class.str.title()\n",
    "\n",
    "# Read in pipeline results and update with the spectroscopic classifications\n",
    "csp_data = Table.read('../results/csp_dr3_simple_fit_class.ecsv')\n",
    "csp_data = csp_data.to_pandas(index='obj_id')\n",
    "csp_data['survey'] = 'CSP'\n",
    "csp_data['spec_class'] = 'Unknown'\n",
    "csp_data.update(csp_spec_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign a \"Normal\" classification to DES sn3yr targets \n",
    "# since it is a cosmology sample\n",
    "\n",
    "des_data = Table.read('../results/des_sn3yr_simple_fit_class.ecsv')\n",
    "des_data = des_data.to_pandas(index='obj_id')\n",
    "des_data['survey'] = 'DES'\n",
    "des_data['spec_class'] = 'Normal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_master = sako18.load_table('master')['CID', 'Classification']\n",
    "sdss_spec_class = pd.DataFrame({\n",
    "    'obj_id': sdss_master['CID'],\n",
    "    'spec_class': sdss_master['Classification']\n",
    "})\n",
    "sdss_spec_class.set_index('obj_id', inplace=True)\n",
    "\n",
    "# Assuming the pipeline is still running:\n",
    "t = Table.read('../results/sdss_sako18_simple_fit_fits.ecsv')\n",
    "from phot_class.classification import classify_targets\n",
    "sdss_data = classify_targets(t).to_pandas(index='obj_id')\n",
    "# sdss_data = Table.read('../results/sdss_sako18_simple_fit_class.ecsv')\n",
    "sdss_data['survey'] = 'SDSS'\n",
    "sdss_data['spec_class'] = 'Unknown'\n",
    "sdss_data.update(sdss_spec_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifications = pd.concat([csp_data, des_data, sdss_data], sort='True')\n",
    "classifications.fillna('Unknown')\n",
    "classifications.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this table we create a static and an interactive version of our classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_static_figure(class_data):\n",
    "    \"\"\"Create a static plot chi-squared difference\n",
    "    \n",
    "    The input DataFrame is expected to have columns x, y, \n",
    "    survey, and spec_class.\n",
    "\n",
    "    Args:\n",
    "        class_data (DataFrame): The data to plot\n",
    "        \n",
    "    Returns:\n",
    "         A matplotlib figure\n",
    "         A matplotlib axis\n",
    "    \"\"\"\n",
    "\n",
    "    markers = {'CSP': 'o', 'DES': 'v', 'SDSS': 's'}\n",
    "\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    for i, release in enumerate(set(class_data['survey'])):\n",
    "        release_data = class_data[class_data['survey'] == release]\n",
    "\n",
    "        for j, sn_type in enumerate(set(class_data['spec_class'])):\n",
    "            plot_data = release_data[release_data['spec_class'] == sn_type]\n",
    "            axis.scatter(\n",
    "                plot_data['x'],\n",
    "                plot_data['y'],\n",
    "                label=sn_type if i == 0 else \"\",\n",
    "                color=f'C{j}',\n",
    "                marker=markers[release],\n",
    "                s=20\n",
    "            )\n",
    "\n",
    "    # axis.axhline(0, linestyle=':', color='black', alpha=.5)\n",
    "    # axis.axvline(0, linestyle=':', color='black', alpha=.5)\n",
    "    axis.set_xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "    axis.set_ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "    axis.legend(bbox_to_anchor=(1, 1))\n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_figure(class_data):\n",
    "    \"\"\"Create an interactive plot chi-squared difference\n",
    "    \n",
    "    The input DataFrame is expected to have columns x, y, \n",
    "    survey, and spec_class.\n",
    "\n",
    "    Args:\n",
    "        class_data (DataFrame): The data to plot\n",
    "        \n",
    "    Returns:\n",
    "         A bokeh figure object\n",
    "    \"\"\"\n",
    "\n",
    "    hover_tooltips = [\n",
    "        (\"obj_id\", \"@obj_id\"),\n",
    "        (\"(x, y)\", \"(@x, @y)\"),\n",
    "        (\"spec_class\", \"@spec_class\"),\n",
    "        (\"survey\", \"@survey\")\n",
    "    ]\n",
    "\n",
    "    fig = figure(\n",
    "        plot_width=600,\n",
    "        plot_height=600,\n",
    "        x_axis_label='Blue chisq (Ia - 91bg)',\n",
    "        y_axis_label='Red chisq (Ia - 91bg)',\n",
    "        tooltips=hover_tooltips\n",
    "    )\n",
    "\n",
    "    # We use the default matplotlib color style\n",
    "    colors = ['#1f77b4',\n",
    "              '#ff7f0e',\n",
    "              '#2ca02c',\n",
    "              '#d62728',\n",
    "              '#9467bd',\n",
    "              '#8c564b',\n",
    "              '#e377c2',\n",
    "              '#7f7f7f',\n",
    "              '#bcbd22',\n",
    "              '#17becf']\n",
    "\n",
    "    markers = {'CSP': 'circle', 'DES': 'inverted_triangle', 'SDSS': 'square'}\n",
    "    for release in set(class_data['survey']):\n",
    "        plot_func = getattr(fig, markers[release])\n",
    "        release_data = class_data[class_data['survey'] == release]\n",
    "\n",
    "        for sn_type, color in zip(set(class_data['spec_class']), colors):\n",
    "            source = release_data[release_data['spec_class'] == sn_type]\n",
    "            plot_func('x', 'y', source=source, legend=sn_type, color=color)\n",
    "\n",
    "    fig.legend.location = \"bottom_right\"\n",
    "    fig.legend.click_policy = \"hide\"\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_fig = create_interactive_figure(classifications)\n",
    "show(interactive_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize FOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a figure of merit (FOM) value as an optimization parameter for training our classification. The FOM is defined as:\n",
    "\n",
    "$$FOM = \\frac{N_{true}}{N_{tot}} * \\frac{N_{true}}{N_{true} + N_{false}}$$\n",
    "\n",
    "where $N_{true}$ is the number of objects correctly classified as a given type (e.g. 91bg-like objects), $N_{tot}$ is the total number of that type, and $N_{false}$ is the number of incorrectly classified objects. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_fom_boundary(fom_type, axis, *args, **kwargs):\n",
    "    \"\"\"Plot the boundaries from an FOM calculation\n",
    "    \n",
    "    Args:\n",
    "        fom_type (str): The type of FOM calculation that was used \n",
    "        axis    (Axis): The matplotlib axis to plot on \n",
    "        *args  (float): The boundaries of the FOM calculation  \n",
    "        **kwargs: Plotting options \n",
    "    \"\"\"\n",
    "    \n",
    "    xlim = axis.get_xlim()\n",
    "    ylim = axis.get_ylim()\n",
    "    if fom_type == 'rectangular':\n",
    "        axis.axhline(args[0], **kwargs)\n",
    "        if 'label' in kwargs:\n",
    "            kwargs.pop('label')\n",
    "\n",
    "        axis.axvline(args[1], **kwargs)\n",
    "        \n",
    "    elif fom_type == 'horizontal':\n",
    "        axis.axvline(args[0], **kwargs)\n",
    "\n",
    "    elif fom_type == 'vertical':\n",
    "        axis.axhline(args[0], **kwargs)\n",
    "\n",
    "    elif fom_type == 'linear':\n",
    "        x = np.array([-1e4, 1e4])\n",
    "        axis.plot(x, args[0] * x + args[1], **kwargs)\n",
    "\n",
    "    elif fom_type == 'diagonal':\n",
    "        x = np.array([-1e4, 1e4])\n",
    "        axis.plot(x, - x + args[0], **kwargs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unknown FOM type {fom_type}')\n",
    "\n",
    "    axis.set_xlim(xlim)\n",
    "    axis.set_ylim(ylim)\n",
    "    axis.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "rectangular_lam = lambda args: 1 - fom.rectangular(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'], \n",
    "    x_cutoff=args[0], \n",
    "    y_cutoff=args[1], \n",
    "    check_type='91bg')\n",
    "\n",
    "rectangular_min = optimize.minimize(rectangular_lam, np.array([0, 0]), method='Powell')\n",
    "x_cutoff, y_cutoff = rectangular_min['x']\n",
    "rectangular_fom = 1 - rectangular_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'rectangular', \n",
    "    static_axis, \n",
    "    x_cutoff, \n",
    "    y_cutoff,\n",
    "    linestyle='--', \n",
    "    color='black', \n",
    "    alpha=.6, \n",
    "    label=f'FOM = {rectangular_fom:.3}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "vertical_lam = lambda args: 1 - fom.vertical(truth=classifications['spec_class'],\n",
    "    y=classifications['y'], \n",
    "    y_cutoff=args[0], \n",
    "    check_type='91bg')\n",
    "\n",
    "vertical_min = optimize.minimize(vertical_lam, np.array([0]), method='Powell')\n",
    "vertical_cutoff = vertical_min['x']\n",
    "vertical_fom = 1 - vertical_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'vertical', \n",
    "    static_axis, \n",
    "    vertical_cutoff, \n",
    "    linestyle='--',\n",
    "    color='black',\n",
    "    alpha=.6, \n",
    "    label=f'FOM = {vertical_fom:.3}')\n",
    "\n",
    "horizontal_lam = lambda args: 1 - fom.horizontal(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    x_cutoff=args[0], \n",
    "    check_type='91bg')\n",
    "\n",
    "horizontal_min = optimize.minimize(horizontal_lam, np.array([0]), method='Powell')\n",
    "horizontal_cutoff = horizontal_min['x']\n",
    "horizontal_fom = 1 - horizontal_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'horizontal', \n",
    "    static_axis, \n",
    "    horizontal_cutoff, \n",
    "    linestyle=':',\n",
    "    color='black',\n",
    "    alpha=.6, \n",
    "    label=f'FOM = {horizontal_fom:.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "diagonal_lam = lambda args: 1 - fom.diagonal(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'],\n",
    "    b=args[0],\n",
    "    check_type='91bg')\n",
    "\n",
    "diagonal_min = optimize.minimize(diagonal_lam, np.array([0]), method='Powell')\n",
    "diagonal_b = diagonal_min['x']\n",
    "diagonal_fom = 1 - diagonal_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'diagonal', \n",
    "    static_axis, \n",
    "    diagonal_b, \n",
    "    linestyle='--', \n",
    "    color='black', \n",
    "    alpha=.6,\n",
    "    label=f'Diagonal FOM ({diagonal_b:.2}) = {diagonal_fom:.3}')\n",
    "\n",
    "linear_lam = lambda args: 1 - fom.linear(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'],\n",
    "    m=args[0],\n",
    "    b=args[1],\n",
    "    check_type='91bg')\n",
    "\n",
    "linear_min = optimize.minimize(linear_lam, np.array([-5, 0]), method='Powell')\n",
    "linear_m, linear_b = linear_min['x']\n",
    "linear_fom = 1 - linear_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'diagonal', \n",
    "    static_axis, \n",
    "    linear_m, \n",
    "    linear_b, \n",
    "    linestyle=':', \n",
    "    color='black', \n",
    "    alpha=.6,\n",
    "    label=f'Linear FOM ({linear_m:.2}, {linear_b:.2})= {linear_fom:.4}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a figure of merit optimization, we can bootstrap our data to determine our final classification parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure bootstrap\n",
    "n_iterations = 100\n",
    "n_size = int(len(classifications) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "fom_values = []\n",
    "classification_params = []\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    sample_data = resample(classifications, n_samples=n_size)\n",
    "    result = optimize.minimize(rectangular_lam, [0, 0], method='Powell')\n",
    "\n",
    "    fom_values.append(1 - result.fun)\n",
    "    classification_params.append(result.x)\n",
    "\n",
    "classification_params = np.array(classification_params).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confidence_intervals(alpha, stats):\n",
    "    p = ((1 - alpha) / 2) * 100\n",
    "    lower = max(0, np.percentile(stats, p))\n",
    "\n",
    "    p = (alpha + ((1 - alpha) / 2)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "alpha=0.95\n",
    "confidence = 0.95\n",
    "average_fom = np.average(fom_values)\n",
    "fom_interval = calc_confidence_intervals(confidence, fom_values)\n",
    "\n",
    "print(f'Average FOM: {average_fom}')\n",
    "print(f'{alpha * 100:.1f} confidence interval: [{fom_interval[0] * 100:.1f} '\n",
    "      f', {fom_interval[1] * 100:.1f}]')\n",
    "\n",
    "average_params = np.average(classification_params, axis=1)\n",
    "blue_param_interval = calc_confidence_intervals(confidence, classification_params[0])\n",
    "red_param_interval = calc_confidence_intervals(confidence, classification_params[1])\n",
    "\n",
    "print(f'Average classification params: {average_params}')\n",
    "print(f'{alpha * 100} confidence interval for blue '\n",
    "      f'boundary: [{blue_param_interval[0]:.2f} '\n",
    "      f', {blue_param_interval[1]:.2f}]')\n",
    "\n",
    "print(f'{alpha * 100} confidence interval for red '\n",
    "      f'boundary: [{red_param_interval[0]:.2f} '\n",
    "      f', {red_param_interval[1]:.2f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phot_class] *",
   "language": "python",
   "name": "conda-env-phot_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
