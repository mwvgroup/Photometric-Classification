{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Photometric Classification To Fit Results\n",
    "\n",
    "This notebook applies the photometric classification method from González-Gaitán et al. 2014 to SDSS, DES, and CSP light-curve fits. Results are then used to analyze the properties of peculiar supernovae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table, vstack\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize\n",
    "from sklearn.utils import resample\n",
    "from sndata.csp import dr1\n",
    "\n",
    "output_notebook()\n",
    "dr1.download_module_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We begin by reading in spectroscopic classificaions for supernovae observed by CSP DR1. We join these classifications with our own classification parameters, and perform some book-keeping along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dr3_class = Table.read('../results/csp_dr3_simple_fit_class.ecsv')\n",
    "dr3_class['Release'] = 'dr3'\n",
    "\n",
    "sn3yr_class = Table.read('../results/des_sn3yr_simple_fit_class.ecsv')\n",
    "sn3yr_class['Release'] = 'sn3yr'\n",
    "\n",
    "photo_class = vstack([dr3_class, sn3yr_class]).to_pandas(index='obj_id')\n",
    "photo_class.dropna(inplace=True)\n",
    "\n",
    "spec_class = dr1.load_table(1)['SN', 'Type']\n",
    "spec_class[spec_class['Type'] == 'peculiar']['Type'] = 'Peculiar'\n",
    "spec_class = spec_class.to_pandas(index='SN')\n",
    "\n",
    "classification = photo_class.join(spec_class)\n",
    "classification['Type'].fillna('Unknown', inplace=True)\n",
    "classification.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us enough information to replicate the classification figure from Gonzalez-Gaitan+ 14. Note that we draw dashed lines intersecting at (0, 0) for visual reference only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_static_figure(class_data):\n",
    "    \"\"\"Create a static plot chi-squared difference\n",
    "    \n",
    "    The input dataframe is expected to have columns x, y, \n",
    "    Release, and Type.\n",
    "\n",
    "    Args:\n",
    "        class_data (DataFrame): The data to plot\n",
    "        \n",
    "    Returns:\n",
    "         A matplotlib figure\n",
    "         A motplotlib axis\n",
    "    \"\"\"\n",
    "        \n",
    "    markers = {'dr3': 'o', 'sn3yr': 'v'}\n",
    "    \n",
    "    fig, axis = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    for i, release in enumerate(set(class_data['Release'])):\n",
    "        release_data = class_data[class_data['Release'] == release]\n",
    "        \n",
    "        for j, sn_type in enumerate(set(class_data['Type'])):\n",
    "            plot_data = release_data[release_data['Type'] == sn_type]\n",
    "            axis.scatter(plot_data['x'], \n",
    "                         plot_data['y'], \n",
    "                         label=sn_type if i == 0 else \"\",\n",
    "                         color=f'C{j}',\n",
    "                         marker=markers[release])\n",
    "\n",
    "    axis.axhline(0, linestyle='--', color='black', alpha=.6)\n",
    "    axis.axvline(0, linestyle='--', color='black', alpha=.6)\n",
    "    axis.set_xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "    axis.set_ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "    axis.legend(bbox_to_anchor=(1, 1))\n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axis = create_static_figure(classification)\n",
    "axis.set_xlim(-6500, 6500)\n",
    "axis.set_ylim(-6500, 6300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_figure(class_data):\n",
    "    \"\"\"Create an interactive plot chi-squared difference\n",
    "    \n",
    "    The input dataframe is expected to have columns x, y, \n",
    "    Release, and Type.\n",
    "\n",
    "    Args:\n",
    "        class_data (DataFrame): The data to plot\n",
    "        \n",
    "    Returns:\n",
    "         A bokeh figure object\n",
    "    \"\"\"\n",
    "    \n",
    "    hover_tooltips = [\n",
    "        (\"obj_id\", \"@obj_id\"),\n",
    "        (\"(x, y)\", \"(@x, @y)\"),\n",
    "        (\"spec_class\", \"@Type\")\n",
    "    ]\n",
    "    \n",
    "    fig = figure(\n",
    "        plot_width=600, \n",
    "        plot_height=600,\n",
    "        x_axis_label='Blue chisq (Ia - 91bg)',\n",
    "        y_axis_label='red chisq (Ia - 91bg)',\n",
    "        tooltips=hover_tooltips\n",
    "    )\n",
    "\n",
    "\n",
    "    # We use the default matplotlib color style\n",
    "    colors = ['#1f77b4',\n",
    "              '#ff7f0e',\n",
    "              '#2ca02c',\n",
    "              '#d62728',\n",
    "              '#9467bd',\n",
    "              '#8c564b',\n",
    "              '#e377c2',\n",
    "              '#7f7f7f',\n",
    "              '#bcbd22',\n",
    "              '#17becf']\n",
    "    \n",
    "    markers = {'dr3': 'circle', 'sn3yr': 'inverted_triangle'}\n",
    "    for release in set(class_data['Release']):\n",
    "        plot_func = getattr(fig, markers[release])\n",
    "        release_data = class_data[class_data['Release'] == release]\n",
    "        \n",
    "        for sn_type, color in zip(set(class_data['Type']), colors):\n",
    "            source = release_data[release_data['Type'] == sn_type]\n",
    "            plot_func('x', 'y', source=source, legend=sn_type, color=color)\n",
    "    \n",
    "    fig.legend.location = \"bottom_right\"\n",
    "    fig.legend.click_policy=\"hide\"\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_indices = np.logical_and(classification['x'] < 10000, classification['y'] < 10000)\n",
    "fig = create_interactive_figure(classification[plot_indices])\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize FOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a figure of merit (FOM) value as an optimization parameter for training our classification. The FOM is defined as:\n",
    "\n",
    "$$FOM = \\frac{N_{true}}{N_{tot}} * \\frac{N_{true}}{N_{true} + N_{false}}$$\n",
    "\n",
    "where $N_{true}$ is the number of correctly identified objects of a given type (e.g. 91bg-like objects), $N_{tot}$ is the total input number of that type and $N_{false}$ is the number of objects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a few functions to determine the optimal chi-squared boundaries based on the FOM. We include functions for two types of classification boundaries. The first calculates the FOM using a verticle and horizontal boundary. The second uses a single boundary at an angle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rect_fom(dataframe, blue_cutoff, red_cutoff):\n",
    "    \"\"\"Calculate the rectangular figure of merrit for a set of classifications\n",
    "    \n",
    "    args:\n",
    "        dataframe   (float): \n",
    "        blue_cutoff (float): \n",
    "        red_cutoff  (float): \n",
    "        \n",
    "    Returns:\n",
    "        The figure of merit value\n",
    "    \"\"\"\n",
    "\n",
    "    is_91bg_true = dataframe['Type'] == '91bg'\n",
    "    is_91bg_classified = (\n",
    "            (dataframe['x'] > blue_cutoff)\n",
    "            & (dataframe['y'] > red_cutoff)\n",
    "    )\n",
    "\n",
    "    num_tot = sum(is_91bg_true)  # How to handle multiple types?\n",
    "    num_true = sum(is_91bg_true == is_91bg_classified)\n",
    "    num_false = len(dataframe) - num_true\n",
    "    return (num_true / num_tot) * (num_true / (num_true + num_false))\n",
    "\n",
    "\n",
    "def calc_diagonal_fom(dataframe, m, b):\n",
    "    \"\"\"Calculate the rectangular figure of merrit for a set of classifications\n",
    "    \n",
    "    args:\n",
    "        dataframe   (float): \n",
    "        blue_cutoff (float): \n",
    "        red_cutoff  (float): \n",
    "        \n",
    "    Returns:\n",
    "        The figure of merit value\n",
    "    \"\"\"\n",
    "\n",
    "    is_91bg_true = dataframe['Type'] == '91bg'\n",
    "    is_91bg_predict = m * dataframe['x'] + b\n",
    "    is_91bg_classified = dataframe['y'] >= is_91bg_predict\n",
    "\n",
    "    num_tot = sum(is_91bg_true)  # How to handle multiple types?\n",
    "    num_true = sum(is_91bg_true == is_91bg_classified)\n",
    "    num_false = len(dataframe) - num_true\n",
    "    return (num_true / num_tot) * (num_true / (num_true + num_false))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Rectangular FOM:')\n",
    "initial_fom = calc_rect_fom(classification, 0, 0)\n",
    "print(f'FOM at (0, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda args: 1 / calc_rect_fom(classification, *args)\n",
    "rect_result = optimize.minimize(inverse_fom, [.1, 0])\n",
    "rect_result['fun'] = 1 / rect_result['fun']\n",
    "print('Optimization results:')\n",
    "print(rect_result)\n",
    "\n",
    "print('\\n\\nAngled FOM:')\n",
    "initial_fom = calc_diagonal_fom(classification, -1, 0)\n",
    "print(f'FOM at (-1, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda args: 1 / calc_diagonal_fom(classification, *args)\n",
    "angl_result = optimize.minimize(inverse_fom, [-1, 0])\n",
    "angl_result['fun'] = 1 / angl_result['fun']\n",
    "print('Optimization results:')\n",
    "print(angl_result)\n",
    "\n",
    "print('\\n\\nAngled FOM at 45 degrees:')\n",
    "initial_fom = calc_diagonal_fom(classification, -1, 0)\n",
    "print(f'FOM at (-1, 0): {initial_fom}\\n')\n",
    "\n",
    "inverse_fom = lambda b: 1 / calc_diagonal_fom(classification, -1, b)\n",
    "angl_45_result = optimize.minimize(inverse_fom, 0)\n",
    "angl_45_result['fun'] = 1 / angl_45_result['fun']\n",
    "print('Optimization results:')\n",
    "print(angl_45_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "a = max(np.abs(classification['x']))\n",
    "line_points = np.array([-a, a])\n",
    "\n",
    "for sn_type in set(classification['Type']):\n",
    "    i = classification['Type'] == sn_type\n",
    "    plt.scatter(classification['x'].loc[i], \n",
    "                classification['y'].loc[i], \n",
    "                label=sn_type)\n",
    "\n",
    "plt.axvline(rect_result.x[0], linestyle='--', color='black', alpha=.6)\n",
    "plt.axhline(rect_result.x[1], linestyle='--', color='black', alpha=.6)\n",
    "\n",
    "# Rectangular FOM\n",
    "plt.axvline(rect_result.x[0], linestyle='--', color='red', alpha=.6)\n",
    "plt.axhline(rect_result.x[1], linestyle='--', color='red', alpha=.6,\n",
    "            label=f'FOM = {rect_result.fun:.4f}')\n",
    "\n",
    "# Angled FOM\n",
    "angl_line = angl_result.x[0] * line_points + angl_result.x[1]\n",
    "plt.plot(line_points, angl_line, linestyle='-', color='orange', alpha=.6,\n",
    "        label=f'FOM = {angl_result.fun:.4f}')\n",
    "\n",
    "# Angled FOM at 45 degrees\n",
    "angl_45_line = -line_points + angl_result.x[0]\n",
    "plt.plot(line_points, angl_45_line, linestyle='-.', color='green', alpha=.6,\n",
    "         label=f'FOM = {angl_45_result.fun:.4f}')\n",
    "\n",
    "plt.xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "plt.ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "plt.xlim(-6000, 6000)\n",
    "plt.ylim(-6000, 6000)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a figure of merit optimization, we can bootstrap our data to determine our final classification parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure bootstrap\n",
    "n_iterations = 1000\n",
    "n_size = int(len(classification) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "fom_values = []\n",
    "classification_params = []\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    sample_data = resample(classification, n_samples=n_size)\n",
    "    inverse_fom = lambda args: 1 / calc_rect_fom(classification, *args)\n",
    "    result = optimize.minimize(inverse_fom, [0, 0])\n",
    "\n",
    "    fom_values.append(1 / result.fun)\n",
    "    classification_params.append(result.x)\n",
    "\n",
    "classification_params = np.array(classification_params).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confidence_intervals(alpha, stats):\n",
    "    p = ((1 - alpha) / 2) * 100\n",
    "    lower = max(0, np.percentile(stats, p))\n",
    "\n",
    "    p = (alpha + ((1 - alpha) / 2)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "alpha=0.95\n",
    "confidence = 0.95\n",
    "average_fom = np.average(fom_values)\n",
    "fom_interval = calc_confidence_intervals(confidence, fom_values)\n",
    "\n",
    "print(f'Average FOM: {average_fom}')\n",
    "print(f'{alpha * 100:.1f} confidence interval: [{fom_interval[0] * 100:.1f} '\n",
    "      f', {fom_interval[1] * 100:.1f}]')\n",
    "\n",
    "average_params = np.average(classification_params, axis=1)\n",
    "blue_param_interval = calc_confidence_intervals(confidence, classification_params[0])\n",
    "red_param_interval = np.average(classification_params[1])\n",
    "\n",
    "print(f'Average classification params: {average_params}')\n",
    "print(f'{alpha * 100:.1f} confidence interval for blue '\n",
    "      f'param: [{blue_param_interval[0] * 100:.1f} '\n",
    "      f', {blue_param_interval[1] * 100:.1f}]')\n",
    "\n",
    "print(f'{alpha * 100:.1f} confidence interval for red '\n",
    "      f'param: [{red_param_interval[0] * 100:.1f} '\n",
    "      f', {red_param_interval[1] * 100:.1f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sdss_chi_diff['blue'], sdss_chi_diff['red'], label='SDSS')\n",
    "plt.scatter(des_chi_diff['blue'], des_chi_diff['red'], label='DES')\n",
    "plt.scatter(csp_chi_diff['blue'], csp_chi_diff['red'], label='CSP')\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.axhline(0, linestyle='--', color='black', alpha=.6)\n",
    "plt.axvline(average_params[0], linestyle='--', color='red', alpha=.6)\n",
    "plt.axhline(average_params[1], linestyle='--', color='red', alpha=.6,\n",
    "            label=f'FOM = {1 / result.fun}')\n",
    "\n",
    "plt.xlabel(r'$\\chi^2_{blue}(Ia) - \\chi^2_{blue}(91bg)$', fontsize=14)\n",
    "plt.ylabel(r'$\\chi^2_{red}(Ia) - \\chi^2_{red}(91bg)$', fontsize=14)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phot_class] *",
   "language": "python",
   "name": "conda-env-phot_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
