{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying SNe\n",
    "\n",
    "This notebook identifies SN91bg-like SNe and compares the results of photometric and spectroscopic classifications.\n",
    "\n",
    "#### Table of Contents:\n",
    "1. <a href='#reading_in_data'>Reading in the Data</a>: Reading in data from both the analysis pipeline and external publications.\n",
    "1. <a href='#spectroscopic_classification'>Spectroscopic Classification</a>: Subtyping of spectroscopically observed targets.\n",
    "1. <a href='#photometric_classification'>Photometric Classification</a>: Subtyping of Photometrically observed targets.\n",
    "1. <a href='#intrinsic_properties'>Intrinsic Properties</a>: Plots of fitted parameters from the classification proccess.\n",
    "1. <a href='#host_properties'>Host Galaxy Properties</a>: Identification of trends with host galaxy mass and SSFR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.cosmology import WMAP9 as wmap9\n",
    "from astropy.table import Table\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "from sndata.csp import dr1\n",
    "from sndata.sdss import sako18, sako18spec\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from phot_class import spectra as spec_class\n",
    "\n",
    "dr1.download_module_data()\n",
    "sako18spec.download_module_data()\n",
    "sako18.download_module_data()\n",
    "\n",
    "# Output directory for figures\n",
    "fig_dir = Path('./notebook_figs/classification')\n",
    "fig_dir.mkdir(exist_ok=True, parents=True)\n",
    "results_dir = Path('../results/').resolve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data <a id='reading_in_data'></a>\n",
    "\n",
    "To save time later on, we read in all of the necessary data in advance. We start with spectroscopic measurements and classifications from external publications. This will allow us to perform a sanity check on our results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sdss classifications\n",
    "sdss_master = sako18.load_table('master')\n",
    "sako_classification = pd.DataFrame({\n",
    "    'obj_id': sdss_master['CID'],\n",
    "    'spec_class': sdss_master['Classification']\n",
    "})\n",
    "sako_classification.set_index('obj_id', inplace=True)\n",
    "sako_classification.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folatelli_13 = dr1.load_table(6).to_pandas()\n",
    "branch_06 = pd.DataFrame({\n",
    "    'obj_id': ['1981B', '1984A', '1986G', '1989B', '1990N', '1991M', '1991T', '1991bg', '1992A', '1994D', '1194ae', '1996X', '1997cn', '1998ag', '1998bu', '1999aw', '1999by', '1999ee', '2000cx', '2001ay', '2001el', '2002bf', '2002bo', '2002cx'],\n",
    "    'pw7': [127, 204, 126, 124, 88, 137, 29, 92, 107, 96, 89, 87, 101, 78, 94, 58, 95, 82, 51, 150, 95, 171, 146, 18 ],\n",
    "    'pw6': [17, 23, 33, 20, 12, 19, 0, 49, 19, 19, 7, 17, 45, 12, 16, 1, 46, 5, 2, 8, 16, 10, 11, 0]\n",
    "})\n",
    "\n",
    "branch_06.set_index('obj_id', inplace=True)\n",
    "branch_06.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we read in spectroscopic measurements from our own analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def calc_julian_date(date):\n",
    "    \"\"\"\n",
    "    Convert a datetime object into julian float.\n",
    "    \n",
    "    Args:\n",
    "        date (str): The date to convert in %Y-%m-%d format\n",
    "\n",
    "    Returns:\n",
    "        The Julian date as a float\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    date = datetime.strptime(date, '%Y-%m-%d')\n",
    "    julian_datetime = (\n",
    "        367 * date.year - \n",
    "        int((7 * (date.year + int((date.month + 9) / 12.0))) / 4.0) + \n",
    "        int((275 * date.month) / 9.0) + date.day + \n",
    "        1721013.5 + \n",
    "        (date.hour + date.minute / 60.0 + date.second / math.pow(60, 2)) / 24.0 - \n",
    "        0.5 * math.copysign(1, 100 * date.year + date.month - 190002.5) + 0.5\n",
    "    )\n",
    "\n",
    "    return julian_datetime\n",
    "\n",
    "\n",
    "def read_spec_results(path):\n",
    "    \"\"\"Read in spectroscopic measurements from the analysis pipeline\n",
    "    \n",
    "    Args:\n",
    "        path (str): The path of the ecsv file to read\n",
    "        \n",
    "    Returns:\n",
    "        A Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in pipeline results\n",
    "    spec_class = Table.read(path).to_pandas()\n",
    "    spec_class.set_index(['obj_id', 'feat_name'], inplace=True)\n",
    "    spec_class['jd'] = calc_julian_date(spec_class.date)\n",
    "    \n",
    "    # Get time of peak brightness\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        master = sako18spec.load_table('master').to_pandas()\n",
    "        master = master.rename(columns={'CID': 'obj_id'}).set_index('obj_id')\n",
    "\n",
    "    # Calculate days since maximum\n",
    "    peak_jd = master.MJDatPeakrmag + 2400000.5\n",
    "    spec_class['days'] = spec_class.jd - peak_jd\n",
    "    \n",
    "    return spec_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spec_results = read_spec_results(results_dir / 'spec_class/sdss_sako18spec_rv3_1_bin5.0_methgauss_step5.ecsv')\n",
    "spec_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we read in the photometric fit results and determine the resulting classification coordinates using the  `classify_targets` function. We included data using band-by-band and collective fitting methods. We also include fit results from `iminuit` and `emcee`. This may take a minute since the `classify_targets` function isn't very well optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phot_class.classification import classify_targets\n",
    "\n",
    "mcmc_coll_fits = Table.read('../results/collective_fits/with_ext/sdss_sako18_mcmc_fit_fits.ecsv')\n",
    "mcmc_coll_class = classify_targets(mcmc_coll_fits).to_pandas().set_index(['obj_id'])\n",
    "mcmc_coll_fits = mcmc_coll_fits.to_pandas().set_index(['source', 'obj_id'])\n",
    "\n",
    "mcmc_band_fits = Table.read('../results/band_fits/with_ext/sdss_sako18_mcmc_fit_fits.ecsv')\n",
    "mcmc_band_class = classify_targets(mcmc_band_fits).to_pandas().set_index(['obj_id'])\n",
    "mcmc_band_fits = mcmc_band_fits.to_pandas().set_index(['source', 'obj_id'])\n",
    "\n",
    "iminuit_coll_fits = Table.read('../results/collective_fits/with_ext/sdss_sako18_simple_fit_fits.ecsv')\n",
    "iminuit_coll_class = classify_targets(iminuit_coll_fits).to_pandas().set_index(['obj_id'])\n",
    "iminuit_coll_fits = iminuit_coll_fits.to_pandas().set_index(['source', 'obj_id'])\n",
    "\n",
    "iminuit_band_fits = Table.read('../results/band_fits/with_ext/sdss_sako18_simple_fit_fits.ecsv')\n",
    "iminuit_band_class = classify_targets(iminuit_band_fits).to_pandas().set_index(['obj_id'])\n",
    "iminuit_band_fits = iminuit_band_fits.to_pandas().set_index(['source', 'obj_id'])\n",
    "\n",
    "iminuit_band_fits.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectroscopic Classification <a id='spectroscopic_classification'></a>\n",
    "\n",
    "This section assigns Branch et al. 2006 style subtypes to SDSS spectra. This classification scheme relies on the pseudo equivalent width (pEW) of Si ii at λ5972 vs λ6355 (here-in refered to as features pW6 and pW7)\n",
    "\n",
    "#### Section Contents:\n",
    "1. <a href='#spectral_binning'>Spectral Binning</a>: A reminder of some of the manipulations performed on each spectrum during the analysis.\n",
    "1. <a href='#selecting_good_data'>Selecting the \"Good\" Data</a>: Selects only measurements near peak brightness and drops results from noisy spectra.\n",
    "1. <a href='#branch'>Branch Classification Plot</a>: Plots Si ii λ5972 vs Si ii λ6355 and assigns subtypes to each SN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Binning <a id='spectral_binning'></a>\n",
    "\n",
    "We pause for a moment and remind ourselves that the values we are working with in this notebook are calculated after each spectra is restframed, corrected for Milky Way extinction, and binned to a resolution of five (unless otherwise noted) angstroms. We choose to use a gaussian filter to reduce the resolution, although options are available for averaging and summing in each bin using the `method` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sako18spec.get_data_for_id('5635')\n",
    "wave = data['wavelength']\n",
    "flux = data['flux']\n",
    "z = data.meta['z']\n",
    "ra = data.meta['ra']\n",
    "dec = data.meta['dec']\n",
    "\n",
    "# Bin the flux and calculate the average in each bin\n",
    "bin_wave, bin_flux = spec_class.bin_spectrum(wave, flux, method='gauss')\n",
    "\n",
    "# Correct for exctinction and shift to rest frame\n",
    "rest_wave, rest_flux = spec_class.correct_extinction(bin_wave, bin_flux, ra, dec, z)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(wave, flux, linewidth=.5, label='Original')\n",
    "plt.plot(bin_wave, bin_flux + 5e-17, linewidth=1, label='Binned Spectrum')\n",
    "plt.plot(rest_wave, rest_flux + 1e-16, linewidth=.5, label='Rest Framed Spectrum')\n",
    "\n",
    "plt.ylim(ymin=0)\n",
    "plt.ylabel('Flux')\n",
    "plt.xlabel(r'Wavelength ($\\AA$)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the \"Good\" Data <a id='selecting_good_data'></a>\n",
    "\n",
    "We start by checking the reasons why some of our calculations failed. Note that range and index related errors are user generated errors during the analysis used to indicate cases where the spectrum was too noisy to identify the feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_results[spec_results.pew.isna()].msg.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the number of observations available for each target. The data release includes targets with multiple observations, however, depending on how the analysis pipeline was run, duplicate observations may have already been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide by two since there are two feature measurments per object.\n",
    "(spec_results.sid.value_counts() / 2).hist()\n",
    "plt.title('Number of spectra per object (Not including host)')\n",
    "plt.ylabel('Number of Targets')\n",
    "plt.xlabel('Number of Spectra')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward we drop results from spectra that:\n",
    "1. Are not measured from the spectrum taken closest to peak brightness.\n",
    "1. Do not have pW7 measurements due to their spectral range.\n",
    "1. Fail visual inspection\n",
    "\n",
    "We start with the first two conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tmax_pew(spec_data):\n",
    "    \"\"\"Keep only pew measurements performed nearest tmax\n",
    "    \n",
    "    Args:\n",
    "        spec_data (DataFrame): Measurements from the analysis pipeline\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Determine what features were measured\n",
    "    features = spec_data.index.get_level_values('feat_name').unique()\n",
    "\n",
    "    data_frames = []\n",
    "    for feat_name in features:\n",
    "        feat_data = spec_data.xs(feat_name, level='feat_name')\n",
    "        feat_data['feat_name'] = feat_name\n",
    "        feat_data.set_index('feat_name', append=True, inplace=True)\n",
    "        \n",
    "        feat_data['sort'] = feat_data.days.abs()         \n",
    "        feat_data = feat_data.sort_values(by='sort')\n",
    "        feat_data = feat_data[~feat_data.index.duplicated()]\n",
    "        feat_data = feat_data.drop(axis=1, labels='sort')\n",
    "        data_frames.append(feat_data)\n",
    "    \n",
    "    all_data = pd.concat(data_frames)\n",
    "    all_data.dropna(subset=['pew'], inplace=True)\n",
    "    \n",
    "    return all_data.loc[all_data.xs('pW7', level='feat_name').index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_results_peak = get_tmax_pew(spec_results)\n",
    "spec_results_peak.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we perform a visual inspection to drop results from any spectra that are particularly noisy. The analysis pipeline already requires the visual inspection of each spectrum, and many noisy spectra may have already been flagged and skipped over. However, the goal of the initial inspection is to be overly ambitious in what we can measure while acknowledging a secondary cut is required later on. We perform that cut here. We also drop spectra with H$\\alpha$ lines, since that indicates a potential problem with the host galaxy subtraction.\n",
    "\n",
    "The following few cells will plot each spectra and ask for an input. Valid inputs are as follows:\n",
    "1. `<Enter>` indicates a good spectrum. \n",
    "1. A number replots the spectrum with a new upper bound\n",
    "1. `n` Means the spectrum is too noisy.\n",
    "1. `h` Indicates a strong H-alpha line\n",
    "1. `r` Indicates the spectrum does not cover enough of the necessary wavelength range.\n",
    "\n",
    "The `start_from` variable can be used to start the iteration process from a given object Id. Results generated by the notebook author are hardcoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = []  # Significant H-alpha\n",
    "noisy = []  # Noisy spectra\n",
    "bad_range = []  # Incomplete wavelength range\n",
    "\n",
    "# Set the object ID to start from. '99999' is higher than any object Id,\n",
    "# thus skipping to the end.\n",
    "start_from = '99999'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "indices = spec_results_peak.index.get_level_values('obj_id').unique()\n",
    "for i, idx in enumerate(sorted(indices)):\n",
    "    if idx < start_from:\n",
    "        continue\n",
    "        \n",
    "    inp = '5e-17'    \n",
    "    while inp:\n",
    "        if inp == 'h':\n",
    "            ha.append(idx)\n",
    "            break\n",
    "            \n",
    "        if inp == 'n':\n",
    "            noisy.append(idx)\n",
    "            break\n",
    "            \n",
    "        if inp == 'r':\n",
    "            bad_range.append(idx)\n",
    "            break\n",
    "            \n",
    "        clear_output()\n",
    "        f, a = plot_outliers(spec_results_peak.loc[[idx]])\n",
    "        a[0].set_ylim(0, float(inp))\n",
    "        plt.show()\n",
    "        inp = input(f'{i}/{len(indices)} ({i / len(indices) * 100:.2f}%)')\n",
    "    \n",
    "    last_index = idx\n",
    "    clear_output()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are results tabulated by the notebook author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = [\n",
    "    '10096', '10805', '12844', '12856', '12874', '12927', '12950', '12977', \n",
    "    '13025', '13070', '13099', '13152', '13174', '13254', '13354', '13467', \n",
    "    '13830', '14261', '14279', '15129', '15136', '15213', '15234', '15467', \n",
    "    '16099', '16099', '16578', '16637', '16692', '16776', '16847', '17176', \n",
    "    '17220', '17389', '17568', '17605', '18375', '18485', '18697', '18903', \n",
    "    '19003', '19008', '19207', '19353', '19626', '19775', '19969', '20142', \n",
    "    '20245', '20528', '21062', '2330', '2635', '2789', '3901', '4524', '5717', \n",
    "    '5751', '6057', '6108', '6249', '6773', '7876', '8921'\n",
    "]\n",
    "\n",
    "noisy = [\n",
    "    '11067', '11300', '11452', '11557', '1166', '13610', '13655', '13689', \n",
    "    '13736', '14421', '15203', '15229', '15287', '15356', '15383', '15456', \n",
    "    '16072', '16350', '16414', '16789', '17048', '18749', '18855', '18890', \n",
    "    '18927', '18959', '19230', '20106', '20144', '20184', '20227', '20345', \n",
    "    '20432', '20581', '20768', '21034', '21510', '2372', '2533', '2689', '3080', \n",
    "    '3199', '3452', '4577', '4679', '6127', '6137', '744', '7475', '7512', '762', \n",
    "    '774', '7947', '8598', '9457', '7143'\n",
    "]\n",
    "\n",
    "bad_range = ['16116', '17171', '17208', '17215', '19616', '19658']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_obj_ids = set(ha + noisy + bad_range)\n",
    "good_spectra = spec_results_peak.drop(bad_obj_ids)\n",
    "print(f'{len(bad_obj_ids)} bad spectra out of {len(spec_results_peak.index.unique())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_spectra(\n",
    "        spec_measurements, xlim=(5000, 7000), space_scale=1.5, num_columns=2):\n",
    "    \"\"\"Plot all spectra used in our data sample with PEW above a given SNR\n",
    "\n",
    "    Args:\n",
    "        spec_measurements: \n",
    "        xlim: \n",
    "        space_scale: \n",
    "        num_columns: \n",
    "\n",
    "    Returns:\n",
    "        A matplotlib figure\n",
    "        A matplotlib axis\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_columns, figsize=(8.5, 11), sharex=True)\n",
    "\n",
    "    # Divide object ids into sperate collections for each figure columns\n",
    "    spec_to_plot = list(spec_measurements.index.get_level_values('obj_id').unique())\n",
    "    spec_per_col = int(np.ceil(len(spec_to_plot) / num_columns))\n",
    "    spectra_cols = [spec_to_plot[i * spec_per_col: (i + 1) * spec_per_col] for i in range(num_columns)]\n",
    "    \n",
    "    for obj_ids_in_column, axis in zip(spectra_cols, axes.flatten()):\n",
    "        \n",
    "        yticks = []\n",
    "        for i, obj_id in enumerate(obj_ids_in_column):\n",
    "            target_data = sako18spec.get_data_for_id(obj_id)\n",
    "            target_measurements = spec_measurements.loc[obj_id]\n",
    "            offset = i * space_scale\n",
    "\n",
    "            # Keep only the SN spectra used in the classification\n",
    "            date = target_measurements.date[0]\n",
    "            target_data = target_data[target_data['date'] == date]\n",
    "            target_data = target_data[target_data['type'] != 'Gal']\n",
    "\n",
    "            # Correct for extinction, shift to rest frame, and bin spectrum\n",
    "            wave = target_data['wavelength']\n",
    "            flux = target_data['flux']\n",
    "            z = target_data.meta['z']\n",
    "            ra = target_data.meta['ra']\n",
    "            dec = target_data.meta['dec']\n",
    "\n",
    "            bin_wave, bin_flux = spec_class.bin_spectrum(wave, flux)\n",
    "            rest_wave, rest_flux = spec_class.correct_extinction(\n",
    "                bin_wave, bin_flux, ra, dec, z)\n",
    "\n",
    "            # Scale and offset spectra to same order of magnitude\n",
    "            _, pw7_end = spec_class.guess_feature_bounds(\n",
    "                rest_wave, rest_flux, spec_class.line_locations['pW7'])\n",
    "            scale = rest_flux[np.where(rest_wave == pw7_end)[0][0]]\n",
    "            rest_flux /= scale\n",
    "            rest_flux += offset\n",
    "\n",
    "            axis.plot(rest_wave, rest_flux, lw=1, color='k')\n",
    "            \n",
    "            # Add the object Id as a tickmark label\n",
    "            min_idx = np.argmin(abs(rest_wave - xlim[0]))\n",
    "            yticks.append(rest_flux[min_idx])\n",
    "\n",
    "        axis.set_ylim(0, (i + 1) * space_scale)\n",
    "        axis.set_yticks(yticks)\n",
    "        axis.set_yticklabels(obj_ids_in_column)\n",
    "        axis.set_xlim(xlim)\n",
    "        axis.set_xlabel('Wavelength')\n",
    "\n",
    "    axes[0].set_ylabel('Candidate Id')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obj_ids = sorted(good_spectra.index.get_level_values('obj_id').unique())\n",
    "\n",
    "# Break object Ids into chuncks and create multiple figures\n",
    "num_figs = 5\n",
    "for i in range(num_figs - 1):\n",
    "    n = len(obj_ids) // num_figs\n",
    "    fig_ids = obj_ids[i * n: (i + 1) * n]\n",
    "    plot_all_spectra(spec_results_peak.loc[fig_ids])\n",
    "    plt.show()\n",
    "\n",
    "fig_ids = obj_ids[(i + 1) * n:]\n",
    "plot_all_spectra(spec_results_peak.loc[fig_ids])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Classification Plot <a id='branch'></a>\n",
    "\n",
    "We plot the pEW of Si ii at λ5972 vs λ6355. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(pw6, pw7):\n",
    "    \"\"\"Get the color of each point bassed on its coordinates\n",
    "    \n",
    "    Args:\n",
    "        pw6 (ndarray): Array of EW measurements for feature 6\n",
    "        pw7 (ndarray): Array of EW measurements for feature 7\n",
    "        \n",
    "    Returns:\n",
    "        A 2d array of RGB values\n",
    "    \"\"\"\n",
    "    \n",
    "    color = np.empty(len(pw6), dtype='U10')\n",
    "    color[:] = 'black'  # Default to black\n",
    "    color[pw6 > 30] = 'blue'  # Blue\n",
    "    color[(pw6 < 30) & (pw7 > 105)] = 'red'  # Red\n",
    "    color[pw7 < 70] = 'green'  # Green\n",
    "\n",
    "    return color\n",
    "\n",
    "def subplot_published_classes(axis):\n",
    "    \"\"\"Plot Si ii pEW at λ5972 vs λ6355 from CSP and Branch 2006\n",
    "    \n",
    "    Args:\n",
    "        axis (Axis): A matplotlib axis\n",
    "    \"\"\"\n",
    "\n",
    "    axis.scatter(\n",
    "        branch_06.pw7, \n",
    "        branch_06.pw6, \n",
    "        marker='D',\n",
    "        facecolor='none', \n",
    "        edgecolor=get_colors(branch_06.pw6, branch_06.pw7),\n",
    "        zorder=2,\n",
    "        alpha=.5,\n",
    "        label='Branch 2006'\n",
    "    )\n",
    "\n",
    "    axis.scatter(\n",
    "        folatelli_13.pW7, \n",
    "        folatelli_13.pW6, \n",
    "        marker='v',\n",
    "        facecolor='none', \n",
    "        edgecolor=get_colors(folatelli_13.pW6, folatelli_13.pW7),\n",
    "        zorder=2,\n",
    "        alpha=.5,\n",
    "        label='Folatelli 2013'\n",
    "    )\n",
    "    \n",
    "def get_pew_above_snr(df, snr):\n",
    "    \"\"\"Return a data frame with only measurements above a given SNR\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Dataframe of spectroscopic pipeline results\n",
    "        snr    (float): The signal to noise ratio\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    lt_7_days = df[df.days.abs() < 7]\n",
    "    good_snr = lt_7_days[lt_7_days.pew / lt_7_days.pew_samperr  >= snr][['pew', 'pew_samperr']]\n",
    "    pw6 = good_snr.xs('pW6', level='feat_name')\n",
    "    pw7 = good_snr.xs('pW7', level='feat_name')\n",
    "    pew = pd.merge(pw6, pw7, on='obj_id', suffixes=('_pw6', '_pw7'))\n",
    "    pew = pew.join(df.date)\n",
    "    return pew\n",
    "    \n",
    "\n",
    "def plot_si_ratio(spec_data, snr_ratios=(1, 2, 3), plot_external_data=True):\n",
    "    \"\"\"Plot the pW6 vs pW7 silicon pEw ratios for different SNR cutoffs\n",
    "    \n",
    "    Args:\n",
    "        spec_data     (DataFrame): Measurements from the analysis pipeline\n",
    "        snr_ratios        (tuple): SNR cutoffs to plot\n",
    "        plot_external_data (bool): Whether to plot data from CSP and Branch 2006\n",
    "        \n",
    "    Returns:\n",
    "        A matplotlib figure\n",
    "        An array of matplotlib axes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keep only Type Ia spectra\n",
    "    si_data = spec_data[spec_data.type.isin(['Ia', 'Ia-pec', 'Ia?'])].dropna(subset=['pew'])\n",
    "    \n",
    "    num_subplots = len(snr_ratios)\n",
    "    fig, axes = plt.subplots(1, num_subplots, figsize=(num_subplots * 6, 6), sharex=True, sharey=True)  \n",
    "    flat_ax = [axes] if num_subplots == 1 else axes.flatten()\n",
    "    for snr, axis in zip(snr_ratios, flat_ax):\n",
    "        \n",
    "        # Keep only data with both pw6 and pw7 measurements greater than snr\n",
    "        plot_data = get_pew_above_snr(si_data, snr)\n",
    "        \n",
    "        axis.errorbar(\n",
    "            x=plot_data.pew_pw7, \n",
    "            y=plot_data.pew_pw6, \n",
    "            xerr=plot_data.pew_samperr_pw7, \n",
    "            yerr=plot_data.pew_samperr_pw6, \n",
    "            linestyle='', \n",
    "            ecolor='grey', \n",
    "            color='grey',\n",
    "            alpha=.3, \n",
    "            zorder=0)\n",
    "        \n",
    "        if plot_external_data:\n",
    "            subplot_published_classes(axis)\n",
    "        \n",
    "        # Isolate each subtype\n",
    "        cl = plot_data[plot_data.pew_pw6 > 30]\n",
    "        bl = plot_data[(plot_data.pew_pw6 < 30) & (plot_data.pew_pw7 > 105)]\n",
    "        ss = plot_data[plot_data.pew_pw7 < 70]\n",
    "        cn = plot_data[(plot_data.pew_pw6 <= 30) & (70 <= plot_data.pew_pw7) & (plot_data.pew_pw7 <= 105)]\n",
    "        \n",
    "        axis.scatter(cl.pew_pw7, cl.pew_pw6, color='C0', zorder=1, label='Cool')\n",
    "        axis.scatter(bl.pew_pw7, bl.pew_pw6, color='C3', zorder=1, label='Broad Line')\n",
    "        axis.scatter(ss.pew_pw7, ss.pew_pw6, color='C2', zorder=1, label='Shallow Silicon')\n",
    "        axis.scatter(cn.pew_pw7, cn.pew_pw6, color='k', zorder=1, label='Core Normal')\n",
    "        \n",
    "        axis.set_xlabel(r'Si ii $\\lambda$6355', fontsize=14)\n",
    "        axis.set_title(rf'SNR $>$ {snr}')\n",
    "        \n",
    "    flat_ax[0].set_xlim(-10, 500)\n",
    "    flat_ax[0].set_ylim(-10, 200)\n",
    "    flat_ax[0].set_ylabel(r'Si ii $\\lambda$5972', fontsize=14) \n",
    "    flat_ax[-1].legend()\n",
    "    return fig, flat_ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the subtypes, we note by using a Gaussian filter to reduce noise, the error bars get artificially small. Values are plotted against results from existing publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_si_ratio(good_spectra, (5, 10, 15, 20))\n",
    "fig.suptitle(f'Branch Si II Subtypes')\n",
    "plt.savefig(fig_dir / 'branch_subtypes.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For curiosity's sake, we investigate the furthest outliers in the first plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(spec_data, pw6_cutoff, pw7_cutoff, snr_cutoff=0):\n",
    "    \"\"\"Select meaurements with pw6 pew > pw6_cutoff and pw7 pew pw7_cutoff\n",
    "    \n",
    "    Args:\n",
    "        spec_data (DataFrame): Data to select on\n",
    "        pw6_cutoff    (float): The PEW cutoff for feature pw6\n",
    "        pw7_cutoff    (float): The PEW cutoff for feature pw7\n",
    "        snr_cutoff    (float): SNR cutoff to apply before selection\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame with measurements matching the specified criteria\n",
    "    \"\"\"\n",
    "    good_snr = spec_data[spec_data.pew / spec_data.pew_samperr > snr_cutoff]\n",
    "\n",
    "    pw6 = good_snr.xs('pW6', level='feat_name')\n",
    "    outliers = set(pw6[pw6.pew > pw6_cutoff].index)\n",
    "\n",
    "    pw7 = good_snr.xs('pW7', level='feat_name')\n",
    "    outliers = list(outliers.intersection(pw7[pw7.pew > pw7_cutoff].index))\n",
    "\n",
    "    outlier_meas = good_snr.loc[outliers]\n",
    "    pw6_indices = set(outlier_meas.xs('pW6', level='feat_name').index)\n",
    "    pw7_indices = set(outlier_meas.xs('pW7', level='feat_name').index)\n",
    "    outliers = sorted(pw6_indices.intersection(pw7_indices))\n",
    "\n",
    "    return good_snr.loc[outliers]\n",
    "\n",
    "def subplot_feature_pew(wave, flux, axis, feat_start, feat_end, **kwargs):\n",
    "    \"\"\"Shade in the PEW of spectral properties\n",
    "\n",
    "    Args:\n",
    "        wave     (ndarray): The spectrum's wavelengths\n",
    "        flux     (ndarray): The flux for each wavelength\n",
    "        axis        (Axis): The axius to plot on\n",
    "        feat_start (float): Where the feature starts\n",
    "        feat_end   (float): Where the feature ends\n",
    "        Any other kwargs for ``axis.fill_between``\n",
    "    \"\"\"\n",
    "\n",
    "    idx_start = np.where(wave == feat_start)[0][0]\n",
    "    idx_end = np.where(wave == feat_end)[0][0]\n",
    "    feat_wave = wave[idx_start: idx_end + 1]\n",
    "    feat_flux = flux[idx_start: idx_end + 1]\n",
    "\n",
    "    continuum, norm_flux, pew = spec_class.feature_pew(feat_wave, feat_flux)\n",
    "    axis.fill_between(feat_wave, feat_flux, continuum, alpha=.75, zorder=0, **kwargs)\n",
    "    \n",
    "\n",
    "def plot_outliers(outlier_data):\n",
    "    \"\"\"Plot a collection of spectra\n",
    "\n",
    "    Args:\n",
    "        outlier_data (DataFrame): PEW Measurements for spectra to plot\n",
    "\n",
    "    Returns:\n",
    "        A matplotlib Figure\n",
    "        An array of matplotlib axes\n",
    "    \"\"\"\n",
    "\n",
    "    obj_ids = outlier_data.index.get_level_values('obj_id').unique()\n",
    "    fig, axes = plt.subplots(len(obj_ids), 1, figsize=(15, 4 * len(obj_ids)), sharex=True)\n",
    "    axes = np.atleast_1d(axes)\n",
    "\n",
    "    for obj_id, axis in zip(obj_ids, axes):\n",
    "        target_data = sako18spec.get_data_for_id(obj_id)\n",
    "        target_data.sort('wavelength')\n",
    "\n",
    "        # Keep only the SN spectra used in the classification\n",
    "        date = outlier_data.loc[obj_id].date[0]\n",
    "        pw6_pew = outlier_data.loc[obj_id, 'pW6'].pew\n",
    "        pw7_pew = outlier_data.loc[obj_id, 'pW7'].pew\n",
    "\n",
    "        target_data = target_data[target_data['date'] == date]\n",
    "        target_data = target_data[target_data['type'] != 'Gal']\n",
    "\n",
    "        # Correct for exctinction and shift to rest frame\n",
    "        wave = target_data['wavelength']\n",
    "        flux = target_data['flux']\n",
    "        z = target_data.meta['z']\n",
    "        ra = target_data.meta['ra']\n",
    "        dec = target_data.meta['dec']\n",
    "        rest_wave, rest_flux = spec_class.correct_extinction(wave, flux, ra, dec, z)\n",
    "        bin_wave, bin_flux = spec_class.bin_spectrum(rest_wave, rest_flux, method='gauss')\n",
    "\n",
    "        axis.plot(rest_wave, rest_flux, lw=1, label='Restframed Spectrum', color='grey', alpha=.75)\n",
    "        for feat_name, row in outlier_data.loc[obj_id].iterrows():\n",
    "            subplot_feature_pew(bin_wave, bin_flux, axis, row.feat_start, row.feat_end, label=feat_name)\n",
    "\n",
    "        axis.plot(bin_wave, bin_flux, lw=2, label='Binned Spectrum', color='k')\n",
    "        axis.set_xlabel('Wavelength')\n",
    "        axis.set_ylabel('Flux')\n",
    "        axis.set_ylim(0, 3e-17)\n",
    "        axis.set_title(f'Object Id: {obj_id}')\n",
    "        \n",
    "    axis.legend()\n",
    "    axis.set_xlim(3000, 7500)\n",
    "\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = get_outliers(good_spectra, 75, 0)\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_outliers(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot a few of the dropped spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_outliers(spec_results_peak.loc[['6304', '7947', '7876']])\n",
    "axes[0].set_ylim(0, .03)\n",
    "axes[0].set_xlabel('')\n",
    "axes[1].set_ylim(0, 6e-17)\n",
    "axes[1].set_xlabel('')\n",
    "axes[2].set_ylim(0, 4e-16)\n",
    "axes[2].set_xlabel(r'Wavlength ($\\AA$)')\n",
    "\n",
    "plt.savefig(fig_dir / 'Dropped_spectra.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometric Classification <a id='photometric_classification'></a>\n",
    "\n",
    "With the spectroscopic classifications in hand, we move on to the photometric data.\n",
    "\n",
    "#### Section Contents:\n",
    "1. <a href='#exploration_of_failed_fits'>Exploration of Failed Fits</a>: A preliminary exploration of the data.\n",
    "1. <a href='#classification'>Classification</a>: Classifying photometrically observed targets.\n",
    "1. <a href='#photometric_vs_spectroscopic'>Photometric V.S. Spectroscopic Classifications</a>: Compares the photometric and spectroscopic results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Failed Fits <a id='exploration_of_failed_fits'></a>\n",
    "\n",
    "We perform a cursory investigation of any fits that have failed to converge. To start, we note the unique error messages raised in the band and collective fit results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failed_fits(fits_df):\n",
    "    \"\"\"Select failed fits from a dataframe\"\"\"\n",
    "    \n",
    "    failed_fits = fits_df.message.str.lower().str.contains('failed')\n",
    "    return fits_df[failed_fits]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Iminuit band fit error messages:\\n')\n",
    "print(get_failed_fits(iminuit_band_fits).message.unique())\n",
    "\n",
    "print('\\nIminuit collective fit error messages:\\n')\n",
    "print(get_failed_fits(iminuit_coll_fits).message.unique())\n",
    "\n",
    "print('\\nMCMC band fit error messages:\\n')\n",
    "print(get_failed_fits(mcmc_band_fits).message.unique())\n",
    "\n",
    "print('\\nMCMC collective fit error messages:\\n')\n",
    "print(get_failed_fits(mcmc_coll_fits).message.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNR error is not concerning so long as there are an equal number of occurences between the band and collective fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_err_msg = 'No data points with S/N > 5.0. Initial guessing failed.'\n",
    "band_snr_indices = iminuit_band_fits.message == snr_err_msg\n",
    "collective_snr_indices = iminuit_coll_fits.message == snr_err_msg\n",
    "equal_errors = sum(band_snr_indices) == sum(collective_snr_indices)\n",
    "\n",
    "print('Equal Number of SNR errors:', equal_errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the SNR errors for now and look at the distribution of the remaining errors across bands and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iminuit_band_fits_goodsnr = iminuit_band_fits[iminuit_band_fits.message != snr_err_msg]\n",
    "iminuit_collective_fits_goodsnr = iminuit_coll_fits[iminuit_coll_fits.message != snr_err_msg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_failed_nosnr = get_failed_fits(iminuit_band_fits_goodsnr)\n",
    "\n",
    "print('Band by band error distribution\\n')\n",
    "print('By fitted band (set):')\n",
    "print(band_failed_nosnr.band.str[-2].value_counts())\n",
    "\n",
    "print('\\nNumber of failed fits per source:')\n",
    "print(band_failed_nosnr.droplevel(1).index.value_counts())\n",
    "\n",
    "print('\\nNumber of failed fits per object (num_failures number_targets):')\n",
    "print(band_failed_nosnr.index.value_counts().value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification <a id='classification'></a>\n",
    "\n",
    "We apply the classification to the fitted light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_delta_chisq(fits_df):\n",
    "    \"\"\"Calculate the difference in reduces chisq for overall fits\n",
    "\n",
    "    Args:\n",
    "        fits_df (DataFrame): Pipeline fit results\n",
    "\n",
    "    Returns:\n",
    "        A pandas series\n",
    "    \"\"\"\n",
    "\n",
    "    fits_hsiao = fits_df.loc['hsiao_x1']\n",
    "    fits_hsiao = fits_hsiao[fits_hsiao.band == 'all']\n",
    "    fits_sn91bg = fits_df.loc['sn91bg']\n",
    "    fits_sn91bg = fits_sn91bg[fits_sn91bg.band == 'all']\n",
    "    return (fits_hsiao.chisq / fits_hsiao.ndof) - (\n",
    "            fits_sn91bg.chisq / fits_sn91bg.ndof)\n",
    "\n",
    "def plot_chisq_scatter(fits_df):\n",
    "    \"\"\"Plot classification results\n",
    "\n",
    "    Args:\n",
    "        fits_df (DataFrame): DataFrame of fit results\n",
    "    \"\"\"\n",
    "    \n",
    "    delta_chi = calc_delta_chisq(fits_df)\n",
    "    chi_lt0 = delta_chi[delta_chi < 0].index\n",
    "    chi_gt0 = delta_chi[delta_chi > 0].index\n",
    "\n",
    "    all_fits =  fits_df[fits_df.band == 'all']\n",
    "    chisq_hs = all_fits.loc['hsiao_x1'].chisq / all_fits.loc['hsiao_x1'].ndof\n",
    "    chisq_bg = all_fits.loc['sn91bg'].chisq / all_fits.loc['sn91bg'].ndof\n",
    "    chisq = pd.DataFrame(dict(chisq_hs=chisq_hs, chisq_bg=chisq_bg))\n",
    "\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(7 / 2, 7 / 2))\n",
    "    labels = (r'$\\Delta\\chi^2 < 0$', r'$\\Delta\\chi^2 > 0$')\n",
    "    for index, label in zip((chi_lt0, chi_gt0), labels):\n",
    "        plot_data = chisq.reindex(index)\n",
    "        axis.scatter(plot_data.chisq_hs, plot_data.chisq_bg, \n",
    "                     s=5, alpha=.2, label=label)\n",
    "\n",
    "    ylim = axis.get_ylim()\n",
    "    axis.plot(ylim, ylim, linestyle='--', color='grey')\n",
    "    axis.set_xscale('log')\n",
    "    axis.set_yscale('log')\n",
    "    axis.set_xlabel(r'Reduced Hsiao $\\chi^2$')\n",
    "    axis.set_ylabel(r'Reduced SN91bg $\\chi^2$')\n",
    "    axis.legend(framealpha=1)\n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq_scat_fig, chisq_scat_axis = plot_chisq_scatter(iminuit_coll_fits)\n",
    "chisq_scat_axis.set_xlim(0, 1e3)\n",
    "chisq_scat_axis.set_ylim(0, 1e3)\n",
    "\n",
    "plt.savefig(fig_dir / 'chisq_scatter.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sako_pec():\n",
    "    \"\"\"Get objects flagged as peculiad in Sako+ 2018\"\"\"\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sako_data = sako18.load_table('master').to_pandas(index='CID')\n",
    "\n",
    "    flagged = sako_data.reindex(sako_data.Notes.dropna().index) \n",
    "    flagged = flagged[flagged.Notes > 1]\n",
    "    return flagged\n",
    "\n",
    "\n",
    "def create_border_hist(axis, padding=0, xpos='top', ypos='right'):\n",
    "    \"\"\"Create axes for plotting border histograms\n",
    "\n",
    "    Args:\n",
    "        axis     (Axis): The matplotlib axis to border\n",
    "        padding (float): Spacing between the main and bordering axes\n",
    "        xpos      (str): Put the x histogram on the 'top' or 'bottom'\n",
    "        ypos      (str): Put the y histogram on the 'left' or 'right'\n",
    "\n",
    "    Returns:\n",
    "        Axis for the upper histogram\n",
    "        Axis for the right side histogram\n",
    "    \"\"\"\n",
    "\n",
    "    axis_pos = axis.get_position()\n",
    "    axis_width = axis_pos.x1 - axis_pos.x0\n",
    "    axis_height = axis_pos.y1 - axis_pos.y0\n",
    "\n",
    "    if xpos == 'top':\n",
    "        histx_pos = axis.get_position()\n",
    "        histx_pos.y0 += axis_height + padding\n",
    "        histx_pos.y1 = histx_pos.y1 + .35 * axis_height + padding\n",
    "        histx = plt.axes(histx_pos)\n",
    "        histx.set_xlim(axis.get_xlim())\n",
    "        histx.tick_params(direction='in', labelbottom=False)\n",
    "        \n",
    "    elif xpos == 'bottom':\n",
    "        histx_pos = axis.get_position()\n",
    "        histx_pos.y1 -= axis_height + padding\n",
    "        histx_pos.y0 = histx_pos.y1 - .35 * axis_height - padding\n",
    "        histx = plt.axes(histx_pos)\n",
    "        histx.set_xlim(axis.get_xlim())\n",
    "        histx.tick_params(direction='in', labelbottom=True)\n",
    "\n",
    "    if ypos == 'right':\n",
    "        histy_pos = axis.get_position()\n",
    "        histy_pos.x0 += axis_width + padding\n",
    "        histy_pos.x1 = histy_pos.x1 + .35 * axis_width + padding\n",
    "        histy = plt.axes(histy_pos)\n",
    "        histy.set_ylim(axis.get_ylim())\n",
    "        histy.tick_params(direction='in', labelleft=False)\n",
    "        \n",
    "    elif ypos == 'left':\n",
    "        histy_pos = axis.get_position()\n",
    "        histy_pos.x1 -= axis_width + padding\n",
    "        histy_pos.x0 = histy_pos.x1 - .35 * axis_width - padding\n",
    "        histy = plt.axes(histy_pos)\n",
    "        histy.set_ylim(axis.get_ylim())\n",
    "        histy.tick_params(direction='in', labelleft=True)\n",
    "\n",
    "    return histx, histy\n",
    "\n",
    "\n",
    "def plot_classification(class_df, fits_df, border_bins, padding, xpos='top', ypos='right', fig=None, axis=None):\n",
    "    \"\"\"Plot classification results\n",
    "\n",
    "    Args:\n",
    "        class_df  (DataFrame): Classification coordinates\n",
    "        class_df  (DataFrame): Classification results from collective fitting\n",
    "        fits_df   (DataFrame): DataFrame of fit results\n",
    "        border_bins (ndarray): Bins for histogram\n",
    "        padding       (float): Spacing between the main and bordering axes\n",
    "        xpos            (str): Put the x histogram on the 'top' or 'bottom'\n",
    "        ypos            (str): Put the y histogram on the 'left' or 'right'\n",
    "        fig          (Figure): Optionally use an existing figure\n",
    "        axis           (Axis): Optionally use an existing axis\n",
    "    \"\"\"\n",
    "\n",
    "    if fig is None or axis is None:\n",
    "        fig, axis = plt.subplots(1, 1, figsize=(7 / 2, 7 / 2))\n",
    "        \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    markers = {2: 's', 3: '^', 4: 'o', 5: 'v'}\n",
    "    labels = {2: '91bg', 3: '00cx', 4: '02ci', 5: '02cx'}\n",
    "\n",
    "    delta_chi = calc_delta_chisq(fits_df)\n",
    "    chi_lt0 = delta_chi[delta_chi < 0]\n",
    "    chi_gt0 = delta_chi[delta_chi > 0]\n",
    "\n",
    "    sako_pec = get_sako_pec()\n",
    "    all_data_lt = class_df.reindex(chi_lt0.index).drop(sako_pec.index, errors='ignore')\n",
    "    all_data_gt = class_df.reindex(chi_gt0.index).drop(sako_pec.index, errors='ignore')\n",
    "    \n",
    "    axis.scatter(all_data_lt.x, all_data_lt.y, s=10, alpha=.7)\n",
    "    axis.scatter(all_data_gt.x, all_data_gt.y, s=10, color='C1', alpha=.7)\n",
    "    \n",
    "    axis.axvline(0, color='grey', linestyle='--')\n",
    "    axis.axhline(0, color='grey', linestyle='--')\n",
    "    axis.set_xlabel(x_label, fontsize=12, labelpad=10)\n",
    "    axis.set_ylabel(y_label, fontsize=12)\n",
    "    axis.set_xlim(min(border_bins), max(border_bins))\n",
    "    axis.set_ylim(-50, 50)\n",
    "    \n",
    "    for flag_type, flag_data in sako_pec.groupby('Notes'):\n",
    "        plt_data = class_df.reindex(flag_data.index)\n",
    "        marker = markers[flag_type]\n",
    "        label = labels[flag_type]\n",
    "        axis.scatter(plt_data.x, plt_data.y, s=20, \n",
    "                     marker=marker, zorder=9,\n",
    "                     color='k', label=label, facecolor='none')\n",
    "\n",
    "    histx, histy = create_border_hist(axis, padding, xpos=xpos, ypos=ypos)\n",
    "    histx.hist([all_data_lt.x, all_data_gt.x], bins=border_bins, stacked=True)\n",
    "    histy.hist([all_data_lt.y, all_data_gt.y], bins=border_bins,\n",
    "               stacked=True, orientation='horizontal')\n",
    "\n",
    "    histx.set_xlim(axis.get_xlim())\n",
    "    histy.set_ylim(axis.get_ylim())\n",
    "    histx.set_yscale('log')\n",
    "    histy.set_xscale('log')\n",
    "    return fig, axis, [histx, histy]\n",
    "\n",
    "\n",
    "def plot_classification_with_subtypes():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(7.5, 7.5), sharex=True, sharey=True)\n",
    "    coll_fig, coll_axes, hist_axes = plot_classification(\n",
    "        class_df=iminuit_band_class, \n",
    "        fits_df=iminuit_band_fits, \n",
    "        border_bins=np.arange(-100, 100, 5),\n",
    "        padding=.01, \n",
    "        fig=fig, \n",
    "        axis=axes[0, 1]\n",
    "    )\n",
    "    \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axes[0, 0].set_ylabel(y_label)\n",
    "    axes[0, 1].set_xlabel('')\n",
    "    axes[0, 1].set_ylabel('')\n",
    "    axes[1, 0].set_ylabel(y_label)\n",
    "    axes[1, 0].set_xlabel(x_label)\n",
    "    axes[1, 1].set_xlabel(x_label)\n",
    "    hist_axes[0].set_ylim(0, 1e4)\n",
    "    hist_axes[1].set_ylim(0, 1e4)\n",
    "\n",
    "    categories = [\n",
    "        ['SNIa', 'pSNIa', 'zSNIa', 'SNIa?'], \n",
    "        ['SNII', 'pSNII', 'zSNII'],\n",
    "        ['pSNIbc', 'zSNIbc', 'SNIc', 'SNIb', 'SNIbc']\n",
    "    ]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sdss_pd = sdss_master.to_pandas()\n",
    "        sdss_pd['obj_id'] = sdss_pd['CID']\n",
    "        sdss_pd.set_index('obj_id', inplace=True)\n",
    "        class_with_sdss = iminuit_coll_class.join(sdss_pd)\n",
    "\n",
    "    for axis, cat in zip(axes.flatten()[[0, 2, 3]], categories):\n",
    "        category_data = class_with_sdss[np.isin(class_with_sdss.Classification, cat)]\n",
    "        for st, data in category_data.groupby('Classification'):\n",
    "            axis.scatter(data.x, data.y, label=st, alpha=.75, s=20)\n",
    "            axis.axvline(0, color='grey', linestyle='--')\n",
    "            axis.axhline(0, color='grey', linestyle='--')\n",
    "            axis.legend()\n",
    "\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-50, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sako_pec():\n",
    "    \"\"\"Get objects flagged as peculiad in Sako+ 2018\"\"\"\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sako_data = sako18.load_table('master').to_pandas(index='CID')\n",
    "\n",
    "    flagged = sako_data.reindex(sako_data.Notes.dropna().index) \n",
    "    flagged = flagged[flagged.Notes > 1]\n",
    "    return flagged\n",
    "\n",
    "\n",
    "def create_border_hist(axis, padding=0, xpos='top', ypos='right'):\n",
    "    \"\"\"Create axes for plotting border histograms\n",
    "\n",
    "    Args:\n",
    "        axis     (Axis): The matplotlib axis to border\n",
    "        padding (float): Spacing between the main and bordering axes\n",
    "        xpos      (str): Put the x histogram on the 'top' or 'bottom'\n",
    "        ypos      (str): Put the y histogram on the 'left' or 'right'\n",
    "\n",
    "    Returns:\n",
    "        Axis for the upper histogram\n",
    "        Axis for the right side histogram\n",
    "    \"\"\"\n",
    "\n",
    "    axis_pos = axis.get_position()\n",
    "    axis_width = axis_pos.x1 - axis_pos.x0\n",
    "    axis_height = axis_pos.y1 - axis_pos.y0\n",
    "\n",
    "    if xpos == 'top':\n",
    "        histx_pos = axis.get_position()\n",
    "        histx_pos.y0 += axis_height + padding\n",
    "        histx_pos.y1 = histx_pos.y1 + .35 * axis_height + padding\n",
    "        histx = plt.axes(histx_pos)\n",
    "        histx.set_xlim(axis.get_xlim())\n",
    "        histx.tick_params(direction='in', labelbottom=False)\n",
    "        \n",
    "    elif xpos == 'bottom':\n",
    "        histx_pos = axis.get_position()\n",
    "        histx_pos.y1 -= axis_height + padding\n",
    "        histx_pos.y0 = histx_pos.y1 - .35 * axis_height - padding\n",
    "        histx = plt.axes(histx_pos)\n",
    "        histx.set_xlim(axis.get_xlim())\n",
    "        histx.tick_params(direction='in', labelbottom=True)\n",
    "\n",
    "    if ypos == 'right':\n",
    "        histy_pos = axis.get_position()\n",
    "        histy_pos.x0 += axis_width + padding\n",
    "        histy_pos.x1 = histy_pos.x1 + .35 * axis_width + padding\n",
    "        histy = plt.axes(histy_pos)\n",
    "        histy.set_ylim(axis.get_ylim())\n",
    "        histy.tick_params(direction='in', labelleft=False)\n",
    "        \n",
    "    elif ypos == 'left':\n",
    "        histy_pos = axis.get_position()\n",
    "        histy_pos.x1 -= axis_width + padding\n",
    "        histy_pos.x0 = histy_pos.x1 - .35 * axis_width - padding\n",
    "        histy = plt.axes(histy_pos)\n",
    "        histy.set_ylim(axis.get_ylim())\n",
    "        histy.tick_params(direction='in', labelleft=True)\n",
    "\n",
    "    return histx, histy\n",
    "\n",
    "\n",
    "def plot_classification(class_df, fits_df, border_bins, padding, xpos='top', ypos='right', fig=None, axis=None):\n",
    "    \"\"\"Plot classification results\n",
    "\n",
    "    Args:\n",
    "        class_df  (DataFrame): Classification coordinates\n",
    "        class_df  (DataFrame): Classification results from collective fitting\n",
    "        fits_df   (DataFrame): DataFrame of fit results\n",
    "        border_bins (ndarray): Bins for histogram\n",
    "        padding       (float): Spacing between the main and bordering axes\n",
    "        xpos            (str): Put the x histogram on the 'top' or 'bottom'\n",
    "        ypos            (str): Put the y histogram on the 'left' or 'right'\n",
    "        fig          (Figure): Optionally use an existing figure\n",
    "        axis           (Axis): Optionally use an existing axis\n",
    "    \"\"\"\n",
    "\n",
    "    if fig is None or axis is None:\n",
    "        fig, axis = plt.subplots(1, 1, figsize=(7 / 2, 7 / 2))\n",
    "        \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    markers = {2: 's', 3: '^', 4: 'o', 5: 'v'}\n",
    "    labels = {2: '91bg', 3: '00cx', 4: '02ci', 5: '02cx'}\n",
    "\n",
    "    delta_chi = calc_delta_chisq(fits_df)\n",
    "    chi_lt0 = delta_chi[delta_chi < 0]\n",
    "    chi_gt0 = delta_chi[delta_chi > 0]\n",
    "\n",
    "    sako_pec = get_sako_pec()\n",
    "    all_data_lt = class_df.reindex(chi_lt0.index).drop(sako_pec.index, errors='ignore')\n",
    "    all_data_gt = class_df.reindex(chi_gt0.index).drop(sako_pec.index, errors='ignore')\n",
    "    \n",
    "    axis.scatter(all_data_lt.x, all_data_lt.y, s=10, alpha=.7)\n",
    "    axis.scatter(all_data_gt.x, all_data_gt.y, s=10, color='C1', alpha=.7)\n",
    "    \n",
    "    axis.axvline(0, color='grey', linestyle='--')\n",
    "    axis.axhline(0, color='grey', linestyle='--')\n",
    "    axis.set_xlabel(x_label, fontsize=12, labelpad=10)\n",
    "    axis.set_ylabel(y_label, fontsize=12)\n",
    "    axis.set_xlim(min(border_bins), max(border_bins))\n",
    "    axis.set_ylim(-50, 50)\n",
    "    \n",
    "    for flag_type, flag_data in sako_pec.groupby('Notes'):\n",
    "        plt_data = class_df.reindex(flag_data.index)\n",
    "        marker = markers[flag_type]\n",
    "        label = labels[flag_type]\n",
    "        axis.scatter(plt_data.x, plt_data.y, s=20, \n",
    "                     marker=marker, zorder=9,\n",
    "                     color='k', label=label, facecolor='none')\n",
    "\n",
    "    histx, histy = create_border_hist(axis, padding, xpos=xpos, ypos=ypos)\n",
    "    histx.hist([all_data_lt.x, all_data_gt.x], bins=border_bins, stacked=True)\n",
    "    histy.hist([all_data_lt.y, all_data_gt.y], bins=border_bins,\n",
    "               stacked=True, orientation='horizontal')\n",
    "\n",
    "    histx.set_xlim(axis.get_xlim())\n",
    "    histy.set_ylim(axis.get_ylim())\n",
    "    histx.set_yscale('log')\n",
    "    histy.set_xscale('log')\n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification(\n",
    "    class_df=iminuit_band_class, \n",
    "    fits_df=iminuit_band_fits, \n",
    "    border_bins=np.arange(-110, 111, 5),\n",
    "    padding=.05\n",
    ")\n",
    "    \n",
    "plt.savefig(fig_dir / 'collective_classification.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification(\n",
    "    class_df=iminuit_coll_class, \n",
    "    fits_df=iminuit_coll_fits, \n",
    "    border_bins=np.arange(-110, 111, 5),\n",
    "    padding=.05\n",
    ")\n",
    "    \n",
    "plt.savefig(fig_dir / 'collective_classification.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification(\n",
    "    class_df=mcmc_band_class, \n",
    "    fits_df=mcmc_band_fits, \n",
    "    border_bins=np.arange(-110, 111, 5),\n",
    "    padding=.05\n",
    ")\n",
    "    \n",
    "plt.savefig(fig_dir / 'collective_classification.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification(\n",
    "    class_df=mcmc_coll_class, \n",
    "    fits_df=mcmc_coll_fits, \n",
    "    border_bins=np.arange(-110, 111, 5),\n",
    "    padding=.05\n",
    ")\n",
    "    \n",
    "plt.savefig(fig_dir / 'collective_classification.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_with_subtypes(classification_coords):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(7.5, 7.5), sharex=True, sharey=True)\n",
    "    \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axes[0, 0].set_ylabel(y_label)\n",
    "    axes[0, 1].set_xlabel('')\n",
    "    axes[0, 1].set_ylabel('')\n",
    "    axes[1, 0].set_ylabel(y_label)\n",
    "    axes[1, 0].set_xlabel(x_label)\n",
    "    axes[1, 1].set_xlabel(x_label)\n",
    "\n",
    "    categories = [\n",
    "        ['SNIa', 'pSNIa', 'zSNIa', 'SNIa?'], \n",
    "        ['SNII', 'pSNII', 'zSNII'],\n",
    "        ['pSNIbc', 'zSNIbc', 'SNIc', 'SNIb', 'SNIbc'], \n",
    "        ['Unknown']\n",
    "    ]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sdss_pd = sako18.load_table('master').to_pandas()\n",
    "        sdss_pd['obj_id'] = sdss_pd['CID']\n",
    "        sdss_pd.set_index('obj_id', inplace=True)\n",
    "        class_with_sdss = classification_coords.join(sdss_pd)\n",
    "\n",
    "    sako_pec = get_sako_pec()\n",
    "    for axis, cat in zip(axes.flatten(), categories):\n",
    "        category_data = class_with_sdss[np.isin(class_with_sdss.Classification, cat)]\n",
    "        for st, data in category_data.groupby('Classification'):\n",
    "            data.drop(sako_pec.index, errors='ignore', inplace=True)\n",
    "            axis.axvline(0, color='grey', linestyle='--', zorder=0)\n",
    "            axis.axhline(0, color='grey', linestyle='--', zorder=0)\n",
    "            axis.scatter(data.x, data.y, label=f'{st} ({len(data)})', alpha=.7, s=10)\n",
    "            axis.legend(loc='upper left', framealpha=1)\n",
    "            \n",
    "        markers = {2: 's', 3: '^', 4: 'o', 5: 'v'}\n",
    "        labels = {2: '91bg', 3: '00cx', 4: '02ci', 5: '02cx'}\n",
    "        for flag_type, flag_data in sako_pec.groupby('Notes'):\n",
    "            plt_data = category_data.reindex(flag_data.index)\n",
    "            marker = markers[flag_type]\n",
    "            axis.scatter(plt_data.x, plt_data.y, s=20, \n",
    "                         marker=marker, zorder=9,\n",
    "                         color='k', facecolor='none')\n",
    "\n",
    "    plt.xlim(-110, 110)\n",
    "    plt.ylim(-55, 55)\n",
    "    \n",
    "    ylabels = np.arange(-50, 51, 10)\n",
    "    ylabels_str = np.array(ylabels, dtype='str')\n",
    "    ylabels_str[::2] = ''\n",
    "    plt.yticks(ylabels, ylabels_str)\n",
    "    \n",
    "    xlabels = np.arange(-100, 101, 20)\n",
    "    xlabels_str = np.array(xlabels, dtype='str')\n",
    "    xlabels_str[::2] = ''\n",
    "    plt.xticks(xlabels, xlabels_str)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=.1, hspace=.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for classification_data in (iminuit_band_class, iminuit_coll_class, mcmc_band_class, mcmc_coll_class):\n",
    "    plot_classification_with_subtypes(classification_data)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photometric V.S. Spectroscopic Classifications <a id='photometric_vs_spectroscopic'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sako_pec():\n",
    "    \"\"\"Get objects flagged as peculiad in Sako+ 2018\"\"\"\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sako_data = sako18.load_table('master').to_pandas(index='CID')\n",
    "\n",
    "    flagged = sako_data.reindex(sako_data.Notes.dropna().index) \n",
    "    flagged = flagged[flagged.Notes > 1]\n",
    "    return flagged\n",
    "\n",
    "pec = get_sako_pec()\n",
    "pec = pec[pec.Notes == 2.0]\n",
    "pec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_with_spec(phot_class, spec_measurements):\n",
    "    \"\"\"Plot classification results\n",
    "\n",
    "    Args:\n",
    "        class_df  (DataFrame): Classification coordinates\n",
    "        class_df  (DataFrame): Classification results from collective fitting\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(7, 7))\n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    markers = dict(blue='s', red='^', black='o', green='v')\n",
    "    labels=dict(blue='Cool', red='Broad Line', green='Shallow Silicon', black='Core Normal')\n",
    "\n",
    "    \n",
    "    spec_measurements['color'] = get_colors(spec_measurements.pew_pw6, spec_measurements.pew_pw7)\n",
    "    plot_data = phot_class.join(spec_measurements)    \n",
    "    \n",
    "    axis.scatter(plot_data.x, plot_data.y, s=10, alpha=.5, color='grey')\n",
    "    for color, data in plot_data.groupby('color'):\n",
    "        axis.scatter(data.x, data.y, s=14, color=color, label=labels[color], marker=markers[color])\n",
    "\n",
    "    sako_results = phot_class.reindex(pec.index)\n",
    "    axis.scatter(sako_results.x, sako_results.y, facecolor='none', edgecolor='black', marker='s')\n",
    "\n",
    "    \n",
    "    axis.axvline(0, color='grey', linestyle='--')\n",
    "    axis.axhline(0, color='grey', linestyle='--')\n",
    "    axis.set_xlabel(x_label, fontsize=12, labelpad=10)\n",
    "    axis.set_ylabel(y_label, fontsize=12)\n",
    "    axis.set_xlim(-75, 75)\n",
    "    axis.set_ylim(-50, 50)\n",
    "    axis.legend()\n",
    "\n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification_with_spec(\n",
    "    phot_class=iminuit_band_class, \n",
    "    spec_measurements=get_pew_above_snr(good_spectra, 0)\n",
    ")\n",
    "\n",
    "plt.title('Iminuit Band-by-Band Fitting')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification_with_spec(\n",
    "    phot_class=iminuit_coll_class, \n",
    "    spec_measurements=get_pew_above_snr(good_spectra, 0)\n",
    ")\n",
    "\n",
    "plt.title('Iminuit Collective Fitting')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification_with_spec(\n",
    "    phot_class=mcmc_band_class, \n",
    "    spec_measurements=get_pew_above_snr(good_spectra, 0)\n",
    ")\n",
    "\n",
    "plt.title('MCMC Band-by-Band Fitting')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_fig, coll_axis = plot_classification_with_spec(\n",
    "    phot_class=mcmc_coll_class, \n",
    "    spec_measurements=get_pew_above_snr(good_spectra, 0)\n",
    ")\n",
    "\n",
    "plt.title('MCMC Collective Fitting')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsic Properties <a id='intrinsic_properties'></a>\n",
    "\n",
    "We consider the distribution of fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_param_histogram(fits_df, source, fit_type, param):\n",
    "    \"\"\"Plot a histagram of fit parameters\n",
    "    \n",
    "    Args:\n",
    "        fits_df (DataFrame): Fit results\n",
    "        source        (str): Name of the model to display results for\n",
    "        fit_type      (str): Use \"band\" or \"collective\" fit results\n",
    "        param         (str): Name of the parameter to plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select data to plot\n",
    "    fits_using_source = fits_df.loc[source]\n",
    "    hist_data = fits_using_source[fits_using_source['band'] == 'all'][param]\n",
    "    \n",
    "    fig, axis = plt.subplots(1, 1, figsize=(7, 7))\n",
    "    axis.hist(hist_data, bins=20)\n",
    "    \n",
    "    latex_safe_source = source.split(\"_\")[0]\n",
    "    axis.set_title(param + f' Distribution ({latex_safe_source} - {fit_type} Fits)'.title())\n",
    "    axis.set_xlabel(param)\n",
    "    axis.set_ylabel('Combined number of targets')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for source in ('hsiao_x1', 'sn91bg'):\n",
    "    for param in ('x1', 'c'):\n",
    "        if source == 'hsiao_x1' and param == 'c':\n",
    "            continue\n",
    "            \n",
    "        for fit_type, fit_data in zip(('band', 'collective'), (iminuit_band_fits, iminuit_coll_fits)):\n",
    "            plot_param_histogram(fit_data, source, fit_type, param)\n",
    "            plt.savefig(fig_dir / f'{param}_{source}_{fit_type}_fits.pdf'.lower())\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for source in ('hsiao_x1', 'sn91bg'):\n",
    "    for param in ('x1', 'c'):\n",
    "        if source == 'hsiao_x1' and param == 'c':\n",
    "            continue\n",
    "            \n",
    "        for fit_type, fit_data in zip(('band', 'collective'), (mcmc_band_fits, mcmc_coll_fits)):\n",
    "            plot_param_histogram(fit_data, source, fit_type, param)\n",
    "            plt.savefig(fig_dir / f'{param}_{source}_{fit_type}_fits.pdf'.lower())\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Galaxy Properties <a id='host_properties'></a>\n",
    "\n",
    "We start with some book keeping and create dataframes for various subsets of the host galaxy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_photometry = pd.DataFrame({\n",
    "    'obj_id': sdss_master['CID'],\n",
    "    'host_id': sdss_master['objIDHost'],  # Host galaxy object ID in SDSS DR8 Database \n",
    "    'ra': sdss_master['RAhost'],  # Right ascension of galaxy host (degrees) \n",
    "    'dec': sdss_master['DEChost'],  # Declination of galaxy host (degrees) \n",
    "    'dist': sdss_master['separationhost'], # Distance from SN to host (arcsec) \n",
    "    'distnorm': sdss_master['DLRhost'], # Normalized distance from SN to host (dDLR) \n",
    "    'z_KF': sdss_master['zphothost'], # Host photometric redshift (KF algorithm) \n",
    "    'z_KF_err': sdss_master['zphoterrhost'], # zphothost uncertainty\n",
    "    'z_RF': sdss_master['zphotRFhost'],  # Host photometric redshift (RF algorithm) \n",
    "    'z_RF_err': sdss_master['zphotRFerrhost'],  # zphotRFhost uncertainty \n",
    "    'u_mag': sdss_master['dereduhost'],  # Host galaxy u-band magnitude (dereddened) \n",
    "    'u_mag_err': sdss_master['erruhost'], # Host galaxy u-band magnitude uncertainty \n",
    "    'g_mag': sdss_master['deredghost'],  # Host galaxy g-band magnitude (dereddened)\n",
    "    'g_mag_err': sdss_master['errghost'],  #  Host galaxy g-band magnitude uncertainty \n",
    "    'r_mag': sdss_master['deredrhost'],  # Host galaxy r-band magnitude (dereddened)\n",
    "    'r_mag_err': sdss_master['errrhost'],  #  Host galaxy r-band magnitude uncertainty \n",
    "    'i_mag': sdss_master['deredihost'], # Host galaxy i-band magnitude (dereddened) \n",
    "    'i_mag_err': sdss_master['errihost'], # Host galaxy i-band magnitude uncertainty \n",
    "    'z_mag': sdss_master['deredzhost'], # Host galaxy z-band magnitude (dereddened) \n",
    "    'z_mag_err': sdss_master['errzhost'] # Host galaxy z-band magnitude (dereddened)\n",
    "})\n",
    "host_photometry.set_index('obj_id', inplace=True)\n",
    "    \n",
    "# Galaxy Parameters Calculated with FSPS\n",
    "fsps_params = pd.DataFrame({\n",
    "    'obj_id' : sdss_master['CID'],\n",
    "    'logmass' : sdss_master['logMassFSPS'],  # FSPS log(M), M=Galaxy Mass (M in units of Me)\n",
    "    'logmass_lo' : sdss_master['logMassloFSPS'],  # FSPS Lower limit of uncertainty in log(M)\n",
    "    'logmass_hi' : sdss_master['logMasshiFSPS'],  # FSPS Upper limit of uncertainty in log(M)\n",
    "    'logssfr' : sdss_master['logSSFRFSPS'],  # FSPS log(sSFR) sSFR=Galaxy Specific Star-forming Rate (SFR in Me yr−1)\n",
    "    'logssfr_lo' : sdss_master['logSSFRloFSPS'],  # FSPS Lower limit of uncertainty in log(sSFR)\n",
    "    'logssfr_hi' : sdss_master['logSSFRhiFSPS'],  # FSPS Upper limit of uncertainty in log(sSFR)\n",
    "    'age' : sdss_master['ageFSPS'],  # FSPS galaxy age (Gyr)\n",
    "    'age_lo' : sdss_master['ageloFSPS'],  # FSPS Lower limit of uncertainty in age\n",
    "    'age_hi' : sdss_master['agehiFSPS'],  # FSPS Upper limit of uncertainty in age \n",
    "    'rchisq' : sdss_master['minredchi2FSPS'] # Reduced chi-squared of best FSPS template fit\n",
    "})\n",
    "fsps_params.set_index('obj_id', inplace=True)\n",
    "\n",
    "# Galaxy Parameters Calculated with PÉGASE.2\n",
    "pegase_params = pd.DataFrame({\n",
    "    'obj_id' : sdss_master['CID'],\n",
    "    'logmass' : sdss_master['logMassPEGASE'], # PÉGASE.2 log(M), M=Galaxy Mass (M in units of Me) \n",
    "    'logmass_lo' : sdss_master['logMassloPEGASE'], # PÉGASE.2 Lower limit of uncertainty in log(M)\n",
    "    'logmass_hi' : sdss_master['logMasshiPEGASE'], # PÉGASE.2 Upper limit of uncertainty in log(SFR) \n",
    "    'logssfr' : sdss_master['logSFRPEGASE'], # PÉGASE.2 log(SFR) SFR=Galaxy star-forming rate (Me yr−1)\n",
    "    'logssfr_lo' : sdss_master['logSFRloPEGASE'], # PÉGASE.2 Lower limit of uncertainty in log(SFR)\n",
    "    'logssfr_hi' : sdss_master['logSFRhiPEGASE'], # PÉGASE.2 Upper limit of uncertainty in log(SFR)\n",
    "    'age' : sdss_master['agePEGASE'], # PÉGASE.2 galaxy age (Gyr)\n",
    "    'rchisq' : sdss_master['minchi2PEGASE']# Reduced chi-squared of best PÉGASE.2 fit\n",
    "})\n",
    "pegase_params.set_index('obj_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also determine the distance of each SN to it's host in kiloparsecs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the redshift values as a pandas array\n",
    "sdss_table_2 = sako18.load_table(2)\n",
    "sdss_table_2['obj_id'] = sdss_table_2['CID']\n",
    "redshift = sdss_table_2['obj_id', 'zspecHelio'].to_pandas('obj_id')\n",
    "\n",
    "# Add distance in kpc\n",
    "host_photometry['arcmin'] = host_photometry.dist / 60\n",
    "host_photometry['kpc'] = wmap9.kpc_comoving_per_arcmin(host_photometry.arcmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_host_property_distribution(col_name, bg_ids, normal_ids, *data_frames, **kwargs):\n",
    "    \"\"\"Plot histograms of host galaxy properties\n",
    "    \n",
    "    Args:\n",
    "    col_name           (str): The name of the value to plot\n",
    "    bg_ids          (Series): Object Ids of 91bg like SN\n",
    "    normal_ids      (Series): Object Ids of normal SN\n",
    "    *data_frames (DataFrame): Data frames with host galaxy data\n",
    "\n",
    "    Returns:\n",
    "        A matplotlib figure\n",
    "        An array of matplotlib axes\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(data_frames))  #, sharex=True, sharey=True)\n",
    "    if len(data_frames) == 1:\n",
    "        axes = np.array([axes])\n",
    "    \n",
    "    for df, axis in zip(data_frames, axes.flatten()):\n",
    "        \n",
    "        plot_data = df[col_name]\n",
    "        bg_data = plot_data.reindex(bg_ids).dropna()\n",
    "        normal_data = plot_data.reindex(normal_ids).dropna()\n",
    "        \n",
    "        aks = stats.anderson_ksamp([normal_data, bg_data])\n",
    "        sig_level = aks.significance_level\n",
    "        \n",
    "        _, bins, _ = axis.hist(\n",
    "            normal_data,\n",
    "            density=True,\n",
    "            label=f'Normal ({len(normal_data)})', \n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        axis.hist(bg_data, \n",
    "                  fill=False, \n",
    "                  hatch='///', \n",
    "                  density=True, \n",
    "                  histtype='step', \n",
    "                  label=f'91bg ({len(bg_data)})',\n",
    "                  bins=bins\n",
    "                 )\n",
    "        \n",
    "        title = r'(p $\\geq$ 0.25)' if sig_level == 0.25 else f'(p = {sig_level:.2})'\n",
    "        axis.set_title(title)\n",
    "\n",
    "    axes[-1].legend()\n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cut = .5\n",
    "y_cut = .5\n",
    "\n",
    "ia_categories = ['SNIa', 'pSNIa', 'zSNIa', 'SNIa?', 'Unknown']\n",
    "ia_indices = sdss_master['CID'][np.isin(sdss_master['Classification'], ia_categories)]\n",
    "ia_subtyped = iminuit_coll_class.reindex(ia_indices)\n",
    "\n",
    "bg_like = ia_subtyped[(ia_subtyped.x > x_cut) & (ia_subtyped.y > y_cut)].index\n",
    "normal = ia_subtyped[(ia_subtyped.x < x_cut) & (ia_subtyped.y < y_cut)].index\n",
    "print(len(bg_like))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_host_property_distribution('logmass', bg_like, normal, fsps_params) \n",
    "\n",
    "axes[0].set_ylabel('Number of Targets', fontsize=16)\n",
    "axes[0].set_title('FSPS ' + axes[0].get_title())\n",
    "# axes[1].set_title('PEGASE ' + axes[1].get_title())\n",
    "for axis in axes:\n",
    "    axis.set_xlabel(r'$\\log($M$_\\odot)$', fontsize=16)\n",
    "    \n",
    "plt.savefig(fig_dir / 'collective_fits_mass.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssfr_data = pegase_params[pegase_params.logssfr > 0]\n",
    "fig, axes = plot_host_property_distribution('logssfr', bg_like, normal, ssfr_data) \n",
    "\n",
    "axes[0].set_xlabel('SSFR', fontsize=16)\n",
    "axes[0].set_ylabel('Number of Targets', fontsize=16)\n",
    "\n",
    "plt.savefig(fig_dir / 'collective_fits_ssfr.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_host_property_distribution('kpc', bg_like, normal, host_photometry) \n",
    "\n",
    "axes[0].set_xlabel('Distance to Host Center (kpc)', fontsize=16)\n",
    "axes[0].set_ylabel('Number of Targets', fontsize=16)\n",
    "\n",
    "plt.savefig(fig_dir / 'collective_fits_distance.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def plot_pvalue(class_df, data, max_x=3.5, max_y=3.5, x_cutoff=0, y_cutoff=0, size=30):\n",
    "    \"\"\"Plot the p-value for host galaxy data as a function of cutoff value\n",
    "    \n",
    "    Args:\n",
    "        class_df (DataFrame): Classification coordinates\n",
    "        data        (Series): Host galaxy\n",
    "        max_x        (float): Maximum for x-axis range\n",
    "        max_y        (float): Maximum for y-axis range\n",
    "        x_cutoff     (float): x classification boundary\n",
    "        y_cutoff     (float): y classification boundary\n",
    "        size         (float): Number of values to sample in x and y direction\n",
    "        \n",
    "    Returns:\n",
    "        A matplotlib figure\n",
    "        An array of matplotlib axes\n",
    "    \"\"\"\n",
    "    \n",
    "    sig_arr = np.zeros((size, size))\n",
    "    count_arr = np.zeros((size, size))\n",
    "    x_arr = np.linspace(0, max_x, sig_arr.shape[0])\n",
    "    y_arr = np.linspace(0, max_y, sig_arr.shape[1])\n",
    "    \n",
    "    dx = (x_arr[1] - x_arr[0]) / 2\n",
    "    dy = (y_arr[1] - y_arr[0]) / 2\n",
    "    extent = [x_arr[0] - dx, x_arr[-1] + dx, y_arr[0] - dy, y_arr[-1] + dy]\n",
    "\n",
    "    for i, xcut in enumerate(x_arr):\n",
    "        for j, ycut in enumerate(y_arr):\n",
    "            test_bg = class_df[(class_df.x > xcut) & (class_df.y > ycut)].index\n",
    "            test_normal = class_df[(class_df.x < xcut) & (class_df.y < ycut)].index\n",
    "            test_bg_data = data.reindex(test_bg).dropna()\n",
    "            test_normal_data = data.reindex(test_normal).dropna()\n",
    "            sig = stats.anderson_ksamp([test_normal_data, test_bg_data]).significance_level\n",
    "            sig_arr[i, j] = sig\n",
    "    \n",
    "    fig, axis = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(7 / 2, 7))\n",
    "    divider = make_axes_locatable(axis)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    im = axis.imshow(sig_arr, extent=extent, origin='lower', cmap='Blues')\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    axis.axvline(x_cutoff, linestyle='--', alpha=.8, color='red')\n",
    "    axis.axhline(y_cutoff, linestyle='--', alpha=.8, color='red')\n",
    "    \n",
    "    axis.set_xlabel('x Cutoff', fontsize=10)\n",
    "    axis.set_ylabel('y Cutoff', fontsize=10)\n",
    "    # axis.contour(x_arr, y_arr, sig_arr, levels=[0.05], colors='red')\n",
    "    \n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, fsps_axis = plot_pvalue(iminuit_coll_class, fsps_params.logmass, x_cutoff=x_cut, y_cutoff=y_cut, size=50) \n",
    "fsps_axis.set_title('Host Mass (FSPS)')\n",
    "plt.savefig(fig_dir / 'fsps_mass_pvalue.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot_pvalue(iminuit_coll_class, pegase_params.logmass, x_cutoff=x_cut, y_cutoff=y_cut) \n",
    "# plt.savefig(fig_dir / 'pegase_mass_pvalue.pdf', bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "_, ssfr_axis = plot_pvalue(iminuit_coll_class, ssfr_data.logssfr, x_cutoff=x_cut, y_cutoff=y_cut) \n",
    "ssfr_axis.set_title('SSFR')\n",
    "plt.savefig(fig_dir / 'ssfr_pvalue.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "_, dist_axis = plot_pvalue(iminuit_coll_class, host_photometry.dist, x_cutoff=x_cut, y_cutoff=y_cut) \n",
    "dist_axis.set_title('Host Distance')\n",
    "plt.savefig(fig_dir / 'dist_pvalue.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_points(class_df, data, max_x=3.5, max_y=3.5, x_cutoff=0, y_cutoff=0, size=30):\n",
    "    \"\"\"Plot the number of 91bgs as a function of the x and y cutoffs\n",
    "    \n",
    "    Args:\n",
    "        class_df (DataFrame): Classification coordinates\n",
    "        data        (Series): Host galaxy\n",
    "        max_x        (float): Maximum for x-axis range\n",
    "        max_y        (float): Maximum for y-axis range\n",
    "        x_cutoff     (float): x classification boundary\n",
    "        y_cutoff     (float): y classification boundary\n",
    "        size         (float): Number of values to sample in x and y direction\n",
    "        \n",
    "    Returns:\n",
    "        A matplotlib figure\n",
    "        An array of matplotlib axes\n",
    "    \"\"\"\n",
    "    \n",
    "    count_arr = np.zeros((size, size))\n",
    "    x_arr = np.linspace(0, max_x, count_arr.shape[0])\n",
    "    y_arr = np.linspace(0, max_y, count_arr.shape[1])\n",
    "    \n",
    "    dx = (x_arr[1] - x_arr[0]) / 2\n",
    "    dy = (y_arr[1] - y_arr[0]) / 2\n",
    "    extent = [x_arr[0] - dx, x_arr[-1] + dx, y_arr[0] - dy, y_arr[-1] + dy]\n",
    "\n",
    "    for i, xcut in enumerate(x_arr):\n",
    "        for j, ycut in enumerate(y_arr):\n",
    "            test_bg = class_df[(class_df.x > xcut) & (class_df.y > ycut)].index\n",
    "            test_bg_data = data.reindex(test_bg).dropna()\n",
    "            count_arr[i, j] = len(test_bg_data)\n",
    "    \n",
    "    # fig, axes = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(7 / 2, 7))\n",
    "    # for axis, plot_data in zip(axes, (count_arr, sig_arr)):\n",
    "    fig, axis = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(7 / 2, 7))\n",
    "    \n",
    "    divider = make_axes_locatable(axis)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    \n",
    "    im = axis.imshow(count_arr, extent=extent, origin='lower', cmap='Blues', vmin=0, vmax=50)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    axis.axvline(x_cutoff, linestyle='--', alpha=.8, color='red')\n",
    "    axis.axhline(y_cutoff, linestyle='--', alpha=.8, color='red')\n",
    "\n",
    "    axis.set_ylabel('y Cutoff', fontsize=10)\n",
    "    axis.set_xlabel('x Cutoff', fontsize=10)\n",
    "    axis.set_title('Number of 91bg points', fontsize=10)\n",
    "    axis.contour(x_arr, y_arr, count_arr, levels=np.arange(0, 51, 10), colors='k')\n",
    "    axis.contour(x_arr, y_arr, count_arr, levels=np.arange(5, 26, 5), colors='k', linestyles=':')\n",
    "    cax_labels = cax.get_yticklabels\n",
    "    \n",
    "    cax.set_yticks(np.arange(0, 51, 10))\n",
    "    cax.set_yticklabels(['0', '10', '20', '30', '40', '50+'])\n",
    "    \n",
    "    return fig, axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_points(iminuit_coll_class, fsps_params.logmass, x_cutoff=x_cut, y_cutoff=y_cut, size=50) \n",
    "plt.savefig(fig_dir / 'num_points.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-phot_class] *",
   "language": "python",
   "name": "conda-env-anaconda3-phot_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
