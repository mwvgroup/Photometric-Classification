{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOM Optimization\n",
    "\n",
    "#### Todo:\n",
    "\n",
    "- Add SNID sybtypes to supliment CSP results\n",
    "- Check why some coordinates are not finite (or maybe their nan? not sure. check this too!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sndata.csp import dr3\n",
    "from sndata.sdss import sako18\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from phot_class import fom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr3.download_module_data()\n",
    "sako18.download_module_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNR Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csp_snr():\n",
    "    \"\"\"Return a 2d array of SNR ratios for each CSP DR3 target\"\"\"\n",
    "    \n",
    "    csp_snr = []\n",
    "    for data_table in dr3.iter_data(verbose=True):\n",
    "        snr = data_table['flux'] /  data_table['fluxerr']\n",
    "        csp_snr.append(np.array(snr))\n",
    "        \n",
    "    return np.array(csp_snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdss_snr(subset=['SNIa']):\n",
    "    \"\"\"Return a 2d array of SNR ratios for each SDSS Sako18 target\n",
    "    \n",
    "    Args:\n",
    "        subset (list): Only consider targets having the\n",
    "                       given Sako18 classifications\n",
    "    \"\"\"\n",
    "    \n",
    "    master = sako18.load_table('master')\n",
    "    is_sn = np.isin(master['Classification'], subset)\n",
    "\n",
    "    sdss_obj_ids = master['CID'][is_sn]\n",
    "\n",
    "    sdss_snr = []\n",
    "    for obj_id in tqdm(sdss_obj_ids):\n",
    "        data_table = sako18.get_data_for_id(obj_id)\n",
    "        snr = data_table['flux'] /  data_table['fluxerr']\n",
    "        sdss_snr.append(np.array(snr))\n",
    "\n",
    "    return np.array(sdss_snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_snr = get_csp_snr()\n",
    "csp_flat = np.concatenate(csp_snr)\n",
    "\n",
    "sdss_snr = get_sdss_snr()\n",
    "sdss_flat = np.concatenate(sdss_snr)\n",
    "sdss_flat = sdss_flat[np.isfinite(sdss_flat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_snr_distributions(csp_snr_arr, sdss_snr_arr):\n",
    "    \"\"\"Plot SNR histograms for CSP and SDSS\n",
    "    \n",
    "    Args:\n",
    "        csp_snr_arr  (ndarray): Flatt array of CSP SNR values\n",
    "        sdss_snr_arr (ndarray): Flatt array of SDSS SNR values\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    ax1.hist(sdss_snr_arr, bins=np.arange(0, 100, 5), label='SDSS', density=False)\n",
    "    ax2.hist(csp_snr_arr, label='CSP', color='C1', density=False)\n",
    "\n",
    "    for survey_data, axis in zip([sdss_snr_arr, csp_snr_arr], (ax1, ax2)):\n",
    "        median = np.median(survey_data)\n",
    "        average = np.average(survey_data)\n",
    "        axis.axvline(median, color='k', linestyle='--', label=f'median {median:.2f}')\n",
    "        axis.axvline(average, color='k', linestyle=':', label=f'average {average:.2f}')\n",
    "\n",
    "        axis.set_xlabel('SNR')\n",
    "        axis.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_snr_distributions(csp_flat, sdss_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale_func = np.average\n",
    "scale_factor =  scale_func(sdss_flat) / scale_func(csp_flat)\n",
    "scale_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Classification Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csp_coords(results_dir):\n",
    "    \"\"\"Load CSP classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        results_dir (Path): Directory containing CSP fit results\n",
    "    \"\"\"\n",
    "\n",
    "    # Load fitted coordinates\n",
    "    csp_path = results_dir / 'csp_dr3_simple_fit_class.ecsv'\n",
    "    csp_coords = Table.read(csp_path).to_pandas('obj_id')\n",
    "    csp_coords['survey'] = 'CSP'\n",
    "\n",
    "    # Load published subtypes from DR3\n",
    "    csp_classes = dr3.load_table(2).to_pandas('SN')\n",
    "    csp_classes = csp_classes.drop(['Dm15(tem)1', 'e_Dm15(tem)1', 'Nopt', 'NIR', 'Tspec'], axis='columns')\n",
    "    csp_classes = csp_classes.rename({k: k.lower() for k in csp_classes.columns}, axis='columns')\n",
    "    csp_classes = csp_classes.replace('---', 'unknown')  # Objects missing subtypes\n",
    "    \n",
    "    return csp_coords.join(csp_classes)\n",
    "\n",
    "\n",
    "def get_sdss_coords(results_dir, snid_path=None):\n",
    "    \"\"\"Load SDSS classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        results_dir (Path): Directory containing SDSS fit results\n",
    "        snid_path   (Path): Optional directory SNID typing results \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load fitted coordinates\n",
    "    sdss_path = results_dir / 'sdss_sako18_simple_fit_class.ecsv'\n",
    "    sdss_coords = Table.read(sdss_path).to_pandas('obj_id')\n",
    "    sdss_coords['survey'] = 'SDSS'\n",
    "    sdss_coords = sdss_coords.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # Load subtypes determined from SNID\n",
    "    if snid_path:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    return sdss_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_results_dir = Path('.').resolve().parent / 'results' / 'band_fits' / 'with_ext'\n",
    "\n",
    "csp_coords = get_csp_coords(ext_results_dir)\n",
    "sdss_coords = get_sdss_coords(ext_results_dir)\n",
    "\n",
    "# Combine coordinates from SDSS and CSP\n",
    "coordinates = pd.concat([csp_coords, sdss_coords])\n",
    "coordinates = coordinates.set_index(['survey', coordinates.index])\n",
    "\n",
    "# Make type column a combination of CSP and SNID subtypes\n",
    "coordinates['type'] = coordinates['subtype1'].fillna('unknown')\n",
    "coordinates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_coord_distributions(\n",
    "        coord_df, \n",
    "        scale, \n",
    "        csp_bins=None, \n",
    "        sdss_bins=np.arange(-100, 100, 2.5),\n",
    "        figsize=(8, 4)):\n",
    "    \"\"\"Plot histogram of classification coords for CSP adnd SDSS\n",
    "    \n",
    "    ``coord_df`` should have columns ``x`` and ``y`` and be indexible\n",
    "    by survey (``CSP`` and ``SDSS``).\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Dataframe of classification coordinates\n",
    "        scale        (float): Rescale csp coordinates by the given value\n",
    "        csp_bins   (ndarray): Bins to use when plotting the CSP histogram\n",
    "        sdss_bins  (ndarray): Bins to use when plotting the CSP histogram\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    for coord, axis in zip('xy', axes):\n",
    "        csp_vals = coord_df.loc['CSP'][coord]\n",
    "        csp_median = np.median(csp_vals)\n",
    "        sdss_vals = coord_df.loc['SDSS'][coord]\n",
    "        sdss_median = np.median(sdss_vals)\n",
    "\n",
    "        axis.hist(csp_vals * scale, bins=csp_bins, density=True, label='csp')\n",
    "        axis.set_title(f'Scale factor: {scale * 100 :.1f}%')\n",
    "        axis.legend()\n",
    "        \n",
    "        twin_x = axis.twinx()\n",
    "        twin_x.hist(sdss_vals * scale, density=True, histtype='step', bins=sdss_bins, label='sdss', color='C1')        \n",
    "        twin_x.set_ylim(0, .01)\n",
    "    \n",
    "    axes[0].set_ylabel('Number of CSP targets')\n",
    "    twin_x.set_ylabel('Number of SDSS targets')\n",
    "    plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_coord_distributions(coordinates, 1)\n",
    "hist_coord_distributions(coordinates, scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_class_coordinates(coord_df, scale=1):\n",
    "    \"\"\"Scatter plot classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "    \"\"\"\n",
    "    \n",
    "    sdss = coord_df.loc['SDSS']\n",
    "    csp = coord_df.loc['CSP']\n",
    "    \n",
    "    fig, axis = plt.subplots()\n",
    "    axis.scatter(sdss['x'], sdss['y'], s=10)\n",
    "    axis.scatter(csp['x'] * scale, csp['y'] * scale, s=5)\n",
    "    \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axis.set_xlabel(x_label)\n",
    "    axis.set_ylabel(y_label)\n",
    "    axis.set_title(f'Scale factor: {scale * 100 :.1f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_class_coordinates(coordinates)\n",
    "plt.xlim(-1500, 1000)\n",
    "\n",
    "scatter_class_coordinates(coordinates)\n",
    "plt.xlim(-40, 50)\n",
    "plt.ylim(-50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_class_coordinates(coordinates, scale_factor)\n",
    "plt.xlim(-1500, 1000)\n",
    "\n",
    "scatter_class_coordinates(coordinates, scale_factor)\n",
    "plt.xlim(-40, 50)\n",
    "plt.ylim(-50, 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_fom(coord_df, x_cut=0, y_cut=0, scale=1, fom=None, figsize=(8, 8)):\n",
    "    \"\"\"Scatter plot classification coordinates and include FOM results\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        x_cut        (float): x cutoff used in FOM calculation\n",
    "        y_cut        (float): y cutoff used in FOM calculation\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axis = plt.subplots(figsize=figsize)\n",
    "\n",
    "    sdss = coord_df.loc['SDSS']\n",
    "    csp = coord_df.loc['CSP']\n",
    "    \n",
    "    axis.scatter(sdss.x, sdss.y, color='grey', alpha=.2)\n",
    "    for sn_type, dataframe in coord_df.loc['CSP'].groupby('type'):  \n",
    "        axis.scatter(dataframe.x * scale, dataframe.y * scale, label=sn_type, s=20)\n",
    "\n",
    "    line_kwargs = dict(linestyle='--', color='black', alpha=.5)\n",
    "    axis.axvline(x_cut, **line_kwargs)\n",
    "    axis.axhline(y_cut, **line_kwargs, label=f'FOM = {fom: .2f}' if fom else fom)\n",
    "        \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axis.set_xlabel(x_label)\n",
    "    axis.set_ylabel(y_label)\n",
    "    \n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "min_method = 'Powell'\n",
    "fom_class = '91bg-like'\n",
    "x0 = [0, 0]\n",
    "\n",
    "fom_coords = coordinates[coordinates.type != 'unknown']\n",
    "def inv_fom(args, scale):\n",
    "    xcut, ycut = args\n",
    "    return 10 / fom.rectangular(\n",
    "        fom_coords.type, \n",
    "        fom_coords.x * scale, \n",
    "        fom_coords.y * scale, \n",
    "        xcut, \n",
    "        ycut,\n",
    "        fom_class)\n",
    "\n",
    "min_res = minimize(\n",
    "    fun=inv_fom, \n",
    "    x0=x0, \n",
    "    method=min_method,\n",
    "    args=scale_factor,\n",
    "    bounds=[\n",
    "        (0, max(fom_coords.x)), \n",
    "        (0, max(fom_coords.y))\n",
    "    ])\n",
    "\n",
    "print('FOM =', 1 / min_res.fun)\n",
    "min_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fom(\n",
    "    coord_df=coordinates, \n",
    "    x_cut=min_res.x[0], \n",
    "    y_cut=min_res.x[1],\n",
    "    scale=scale_factor, \n",
    "    fom=1 / min_res.fun)\n",
    "\n",
    "plt.xlim(-50, 50)\n",
    "plt.ylim(-50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "from bokeh.models import Span\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "def bokeh_fom(coord_df, x_cut=0, y_cut=0, scale=1, fom=None, figsize=(8, 8)):\n",
    "    \"\"\"Scatter plot classification coordinates and include FOM results\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        x_cut        (float): x cutoff used in FOM calculation\n",
    "        y_cut        (float): y cutoff used in FOM calculation\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    #fig, axis = plt.subplots(figsize=figsize)\n",
    "\n",
    "    sdss = coord_df.loc['SDSS']\n",
    "    csp = coord_df.loc['CSP']\n",
    "\n",
    "    colors = itertools.cycle(palette) \n",
    "    fig = figure(plot_width=800, plot_height=800)\n",
    "    \n",
    "    fig.circle(sdss.x, sdss.y, color='grey', alpha=.2)\n",
    "    for sn_type, dataframe in coord_df.loc['CSP'].groupby('type'):  \n",
    "        fig.circle(dataframe.x * scale, dataframe.y * scale, color=next(colors))\n",
    "\n",
    "    fig.ray(x=[y_cut], y=[y_cut], length=0, angle=0, line_width=1, color='black')\n",
    "    fig.ray(x=[y_cut], y=[y_cut], length=0, angle=np.pi, line_width=1, color='black')\n",
    "    \n",
    "    fig.ray(x=[x_cut], y=[x_cut], length=0, angle=-np.pi / 2, line_width=1, color='black')\n",
    "    fig.ray(x=[x_cut], y=[x_cut], length=0, angle=np.pi / 2, line_width=1, color='black')\n",
    "\n",
    "    # line_kwargs = dict(linestyle='--', color='black', alpha=.5)\n",
    "    # axis.axvline(x_cut, **line_kwargs)\n",
    "    # axis.axhline(y_cut, **line_kwargs, label=f'FOM = {fom: .2f}' if fom else fom)\n",
    "        \n",
    "    fig.xaxis.axis_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    fig.yaxis.axis_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    fig.x_range = Range1d(-100, 100)\n",
    "    fig.y_range = Range1d(-100, 100)\n",
    "    show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_fom(\n",
    "    coord_df=coordinates, \n",
    "    x_cut=min_res.x[0], \n",
    "    y_cut=min_res.x[1],\n",
    "    scale=scale_factor, \n",
    "    fom=1 / min_res.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Photometric-Classification] *",
   "language": "python",
   "name": "conda-env-Photometric-Classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
