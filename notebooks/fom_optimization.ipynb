{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOM Optimization\n",
    "\n",
    "#### Todo:\n",
    "\n",
    "- Check why some SDSS coordinates are not finite (or maybe their nan? not sure. check this too!).\n",
    "- Determine values for collective and band fitting\n",
    "- Determine values for sifto results\n",
    "- Drop targets that disagree SNID vs SDSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from sndata.csp import dr3\n",
    "from sndata.sdss import sako18\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from phot_class import fom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr3.download_module_data()\n",
    "sako18.download_module_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNR Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csp_snr():\n",
    "    \"\"\"Return a 2d array of SNR ratios for each CSP DR3 target\"\"\"\n",
    "    \n",
    "    csp_snr = []\n",
    "    for data_table in dr3.iter_data(verbose=True):\n",
    "        snr = data_table['flux'] /  data_table['fluxerr']\n",
    "        csp_snr.append(np.array(snr))\n",
    "        \n",
    "    return np.array(csp_snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdss_snr(subset=['SNIa']):\n",
    "    \"\"\"Return a 2d array of SNR ratios for each SDSS Sako18 target\n",
    "    \n",
    "    Args:\n",
    "        subset (list): Only consider targets having the\n",
    "                       given Sako18 classifications\n",
    "    \"\"\"\n",
    "    \n",
    "    master = sako18.load_table('master')\n",
    "    is_sn = np.isin(master['Classification'], subset)\n",
    "\n",
    "    sdss_obj_ids = master['CID'][is_sn]\n",
    "\n",
    "    sdss_snr = []\n",
    "    for obj_id in tqdm(sdss_obj_ids):\n",
    "        data_table = sako18.get_data_for_id(obj_id)\n",
    "        snr = data_table['flux'] /  data_table['fluxerr']\n",
    "        sdss_snr.append(np.array(snr))\n",
    "\n",
    "    return np.array(sdss_snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_snr = get_csp_snr()\n",
    "csp_flat = np.concatenate(csp_snr)\n",
    "\n",
    "sdss_snr = get_sdss_snr()\n",
    "sdss_flat = np.concatenate(sdss_snr)\n",
    "sdss_flat = sdss_flat[np.isfinite(sdss_flat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_snr_distributions(csp_snr_arr, sdss_snr_arr):\n",
    "    \"\"\"Plot SNR histograms for CSP and SDSS\n",
    "    \n",
    "    Args:\n",
    "        csp_snr_arr  (ndarray): Flatt array of CSP SNR values\n",
    "        sdss_snr_arr (ndarray): Flatt array of SDSS SNR values\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    ax1.hist(sdss_snr_arr, bins=np.arange(0, 100, 5), label='SDSS', density=False)\n",
    "    ax2.hist(csp_snr_arr, label='CSP', color='C1', density=False)\n",
    "\n",
    "    for survey_data, axis in zip([sdss_snr_arr, csp_snr_arr], (ax1, ax2)):\n",
    "        median = np.median(survey_data)\n",
    "        average = np.average(survey_data)\n",
    "        axis.axvline(median, color='k', linestyle='--', label=f'median {median:.2f}')\n",
    "        axis.axvline(average, color='k', linestyle=':', label=f'average {average:.2f}')\n",
    "\n",
    "        axis.set_xlabel('SNR')\n",
    "        axis.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_snr_distributions(csp_flat, sdss_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale_func = np.median\n",
    "scale_factor =  scale_func(sdss_flat) / scale_func(csp_flat)\n",
    "scale_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Classification Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csp_coords(results_dir):\n",
    "    \"\"\"Load CSP classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        results_dir (Path): Directory containing CSP fit results\n",
    "    \"\"\"\n",
    "\n",
    "    # Load fitted coordinates\n",
    "    csp_path = results_dir / 'csp_dr3_simple_fit_class.ecsv'\n",
    "    csp_coords = Table.read(csp_path).to_pandas('obj_id')\n",
    "    csp_coords['survey'] = 'CSP'\n",
    "\n",
    "    # Load published subtypes from DR3\n",
    "    csp_classes = dr3.load_table(2).to_pandas('SN')\n",
    "    csp_classes = csp_classes.drop(['Dm15(tem)1', 'e_Dm15(tem)1', 'Nopt', 'NIR', 'Tspec'], axis='columns')\n",
    "    csp_classes = csp_classes.rename({'Subtype1': 'type', 'Subtype2': 'Branch', 'Subtype3': 'Wang'}, axis='columns')\n",
    "    \n",
    "    csp_classes = csp_classes.replace('---', 'unknown')  # Objects missing subtypes\n",
    "    csp_classes = csp_classes.replace('normal', 'Ia-norm')\n",
    "    csp_classes = csp_classes.replace('91bg-like', 'Ia-91bg')\n",
    "    csp_classes = csp_classes.replace('91T-like', 'Ia-91T')\n",
    "    \n",
    "    return csp_coords.join(csp_classes)\n",
    "\n",
    "\n",
    "def read_peak_subtype(path):\n",
    "    \"\"\"Return the type summary from an SNID output file\n",
    "\n",
    "    Args:\n",
    "        path (str, Path): Path to read\n",
    "\n",
    "    Returns:\n",
    "         An astropy Table\n",
    "    \"\"\"\n",
    "\n",
    "    names = ['type', 'ntemp', 'fraction', 'slope', 'redshift',\n",
    "             'redshift_error', 'age', 'age_error']\n",
    "\n",
    "    data = Table.read(\n",
    "        str(path), header_start=4, data_start=4,\n",
    "        data_end=28, format='ascii.basic', names=names\n",
    "    ).to_pandas(index='type')\n",
    "    \n",
    "    sn_type, subtype, second_subtype = data.ntemp.nlargest(3).index\n",
    "    assert data.loc[subtype].ntemp != second_subtype\n",
    "    ntemp = data.loc[subtype].ntemp\n",
    "    perc_temp = ntemp / data.loc[sn_type].ntemp\n",
    "\n",
    "    return subtype, ntemp, perc_temp\n",
    "\n",
    "\n",
    "def compile_peak_subtypes(results_dir):\n",
    "    \"\"\"Get peak subtypes from all output files from a previous SNID run\n",
    "\n",
    "    Args:\n",
    "        results_dir (Path): Directory of SNID outputs\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame indexed by object ID\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = []\n",
    "    for path in results_dir.glob('*snid.output'):\n",
    "        obj_id, phase, *_ = path.name.split('_')\n",
    "        peak_type, ntemp, perc_temp = read_peak_subtype(path)\n",
    "        rows.append([obj_id, float(phase), peak_type, ntemp, perc_temp])\n",
    "\n",
    "    type_data = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=['obj_id', 'phase', 'type', 'ntemp', 'perc_temp'])\n",
    "\n",
    "    # Keep only the spectra nearest peak\n",
    "    type_data['abs_phase'] = type_data.phase.abs()\n",
    "    type_data = type_data.sort_values('abs_phase', ascending=True)\n",
    "    type_data = type_data.drop_duplicates(keep='first', subset='obj_id')\n",
    "\n",
    "    type_data['obj_id'] = type_data['obj_id'].astype('str')\n",
    "    return type_data.set_index('obj_id')\n",
    "\n",
    "\n",
    "def get_sdss_coords(results_dir, snid_dir=None):\n",
    "    \"\"\"Load SDSS classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        results_dir (Path): Directory containing SDSS fit results\n",
    "        snid_path   (Path): Optional directory SNID typing results \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load fitted coordinates\n",
    "    sdss_path = results_dir / 'sdss_sako18_simple_fit_class.ecsv'\n",
    "    sdss_coords = Table.read(sdss_path).to_pandas('obj_id')\n",
    "    sdss_coords['survey'] = 'SDSS'\n",
    "    sdss_coords = sdss_coords.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    # Load subtypes determined from SNID\n",
    "    subtypes_rlap_5_path = snid_dir / 'subtype_rlap_5'\n",
    "    subtypes_rlap_5 = compile_peak_subtypes(subtypes_rlap_5_path)\n",
    "\n",
    "    subtypes_rlap_10_path = snid_dir / 'subtype_rlap_10'\n",
    "    subtypes_rlap_10 = compile_peak_subtypes(subtypes_rlap_10_path)\n",
    "\n",
    "    subtypes_rlap_5.update(subtypes_rlap_10)\n",
    "    sdss_coords['type'] = subtypes_rlap_5['type']\n",
    "    sdss_coords['type'] = sdss_coords['type'].fillna('unknown')\n",
    "        \n",
    "    return sdss_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_or_collective = 'collective'\n",
    "ext_results_dir = Path('.').resolve().parent / 'results' / f'{band_or_collective}_fits' / 'with_ext'\n",
    "snid_results_dir = Path('.').resolve().parent / 'results' / 'snid'\n",
    "csp_coords = get_csp_coords(ext_results_dir)\n",
    "sdss_coords = get_sdss_coords(ext_results_dir, snid_results_dir)\n",
    "\n",
    "# Combine coordinates from SDSS and CSP\n",
    "coordinates = pd.concat([csp_coords, sdss_coords])\n",
    "coordinates = coordinates.set_index(['survey', coordinates.index])\n",
    "\n",
    "# Make type column a combination of CSP and SNID subtypes\n",
    "coordinates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_coord_distributions(\n",
    "        coord_df, \n",
    "        scale, \n",
    "        csp_bins=None, \n",
    "        sdss_bins=np.arange(-100, 100, 2.5),\n",
    "        figsize=(8, 4)):\n",
    "    \"\"\"Plot histogram of classification coords for CSP adnd SDSS\n",
    "    \n",
    "    ``coord_df`` should have columns ``x`` and ``y`` and be indexible\n",
    "    by survey (``CSP`` and ``SDSS``).\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Dataframe of classification coordinates\n",
    "        scale        (float): Rescale csp coordinates by the given value\n",
    "        csp_bins   (ndarray): Bins to use when plotting the CSP histogram\n",
    "        sdss_bins  (ndarray): Bins to use when plotting the CSP histogram\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    for coord, axis in zip('xy', axes):\n",
    "        csp_vals = coord_df.loc['CSP'][coord]\n",
    "        csp_median = np.median(csp_vals)\n",
    "        sdss_vals = coord_df.loc['SDSS'][coord]\n",
    "        sdss_median = np.median(sdss_vals)\n",
    "\n",
    "        axis.hist(csp_vals * scale, bins=csp_bins, density=True, label='csp')\n",
    "        axis.set_title(f'Scale factor: {scale * 100 :.1f}%')\n",
    "        axis.legend()\n",
    "        \n",
    "        twin_x = axis.twinx()\n",
    "        twin_x.hist(sdss_vals, density=True, histtype='step', bins=sdss_bins, label='sdss', color='C1')        \n",
    "        twin_x.set_ylim(0, .01)\n",
    "    \n",
    "    axes[0].set_ylabel('Number of CSP targets')\n",
    "    twin_x.set_ylabel('Number of SDSS targets')\n",
    "    plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_coord_distributions(coordinates, 1)\n",
    "hist_coord_distributions(coordinates, scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_class_coordinates(coord_df, scale=1):\n",
    "    \"\"\"Scatter plot classification coordinates\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "    \"\"\"\n",
    "    \n",
    "    sdss = coord_df.loc['SDSS']\n",
    "    csp = coord_df.loc['CSP']\n",
    "    \n",
    "    fig, axis = plt.subplots()\n",
    "    axis.scatter(sdss['x'], sdss['y'], s=10)\n",
    "    axis.scatter(csp['x'] * scale, csp['y'] * scale, s=5)\n",
    "    \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axis.set_xlabel(x_label)\n",
    "    axis.set_ylabel(y_label)\n",
    "    axis.set_title(f'Scale factor: {scale * 100 :.1f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_class_coordinates(coordinates)\n",
    "plt.xlim(-1500, 1000)\n",
    "plt.ylim(-3000, 2000)\n",
    "\n",
    "scatter_class_coordinates(coordinates)\n",
    "plt.xlim(-100, 100)\n",
    "plt.ylim(-100, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_class_coordinates(coordinates, scale_factor)\n",
    "plt.xlim(-1500, 1000)\n",
    "plt.ylim(-3000, 2000)\n",
    "\n",
    "scatter_class_coordinates(coordinates, scale_factor)\n",
    "plt.xlim(-100, 100)\n",
    "plt.ylim(-100, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "min_method = 'Powell'\n",
    "fom_class = 'Ia-91bg'\n",
    "x0 = [0, 0]\n",
    "\n",
    "fom_coords = coordinates[coordinates.type != 'unknown']\n",
    "def inv_fom(args, scale):\n",
    "    xcut, ycut = args\n",
    "    return 1 / fom.rectangular(\n",
    "        fom_coords.type, \n",
    "        fom_coords.x * scale, \n",
    "        fom_coords.y * scale, \n",
    "        xcut, \n",
    "        ycut,\n",
    "        fom_class)\n",
    "\n",
    "min_res = minimize(\n",
    "    fun=inv_fom, \n",
    "    x0=x0, \n",
    "    method=min_method,\n",
    "    args=scale_factor,\n",
    "    bounds=[\n",
    "        (0, max(fom_coords.x)), \n",
    "        (0, max(fom_coords.y))\n",
    "    ])\n",
    "\n",
    "print('FOM =', 1 / min_res.fun)\n",
    "min_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_fom(coord_df, x_cut=0, y_cut=0, scale=1, fom=None, figsize=(8, 8)):\n",
    "    \"\"\"Scatter plot classification coordinates and include FOM results\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        x_cut        (float): x cutoff used in FOM calculation\n",
    "        y_cut        (float): y cutoff used in FOM calculation\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axis = plt.subplots(figsize=figsize)\n",
    "    for sn_type, dataframe in coord_df.groupby('type'): \n",
    "        if sn_type == 'unknown':\n",
    "            axis.scatter(dataframe.x, dataframe.y, color='grey', alpha=.2, zorder=-1)\n",
    "        \n",
    "        else:    \n",
    "            label = f'{sn_type} ({len(dataframe)})'\n",
    "            axis.scatter(dataframe.x * scale, dataframe.y * scale, label=label, s=20)\n",
    "\n",
    "    line_kwargs = dict(linestyle='--', color='black', alpha=.5)\n",
    "    axis.axvline(x_cut, **line_kwargs)\n",
    "    axis.axhline(y_cut, **line_kwargs, label=f'FOM = {fom: .2f}' if fom else fom)\n",
    "        \n",
    "    x_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    y_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    axis.set_xlabel(x_label)\n",
    "    axis.set_ylabel(y_label)\n",
    "    \n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fom(\n",
    "    coord_df=coordinates, \n",
    "    x_cut=min_res.x[0], \n",
    "    y_cut=min_res.x[1],\n",
    "    scale=scale_factor, \n",
    "    fom=1 / min_res.fun)\n",
    "\n",
    "plt.xlim(-100, 100)\n",
    "plt.ylim(-100, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "from bokeh.io import  output_notebook\n",
    "\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_fom(coord_df, x_cut=0, y_cut=0, scale=1, fom=None, figsize=(8, 8)):\n",
    "    \"\"\"Scatter plot classification coordinates and include FOM results\n",
    "    \n",
    "    Args:\n",
    "        coord_df (dataframe): Classification coordinates for CSP and SDSS\n",
    "        x_cut        (float): x cutoff used in FOM calculation\n",
    "        y_cut        (float): y cutoff used in FOM calculation\n",
    "        scale        (float): Rescale CSP coordinates by the given value\n",
    "        figsize      (tuple): Size of the figure in inches\n",
    "    \"\"\"\n",
    "    \n",
    "    colors = itertools.cycle(palette) \n",
    "    fig = figure(plot_width=800, plot_height=800)\n",
    "    \n",
    "    \n",
    "    for sn_type, dataframe in coord_df.groupby('type'): \n",
    "        if sn_type == 'unknown':\n",
    "            continue\n",
    "        \n",
    "        fig.circle(dataframe.x * scale, dataframe.y * scale, color=next(colors))\n",
    "\n",
    "    fig.ray(x=[y_cut], y=[y_cut], length=0, angle=0, line_width=1, color='black')\n",
    "    fig.ray(x=[y_cut], y=[y_cut], length=0, angle=np.pi, line_width=1, color='black')\n",
    "    \n",
    "    fig.ray(x=[x_cut], y=[x_cut], length=0, angle=-np.pi / 2, line_width=1, color='black')\n",
    "    fig.ray(x=[x_cut], y=[x_cut], length=0, angle=np.pi / 2, line_width=1, color='black')\n",
    "\n",
    "    fig.xaxis.axis_label = r'$\\chi^2_{blue}$ (Ia) - $\\chi^2_{blue}$ (91bg)'\n",
    "    fig.yaxis.axis_label = r'$\\chi^2_{red}$ (Ia) - $\\chi^2_{red}$ (91bg)'\n",
    "    fig.x_range = Range1d(-100, 100)\n",
    "    fig.y_range = Range1d(-100, 100)\n",
    "    show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_fom(\n",
    "    coord_df=coordinates, \n",
    "    x_cut=min_res.x[0], \n",
    "    y_cut=min_res.x[1],\n",
    "    scale=scale_factor, \n",
    "    fom=1 / min_res.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Photometric-Classification] *",
   "language": "python",
   "name": "conda-env-Photometric-Classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
