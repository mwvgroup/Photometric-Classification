{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOM Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a figure of merit (FOM) value as an optimization parameter for training our classification. The FOM is defined as:\n",
    "\n",
    "$$FOM = \\frac{N_{true}}{N_{tot}} * \\frac{N_{true}}{N_{true} + N_{false}}$$\n",
    "\n",
    "where $N_{true}$ is the number of objects correctly classified as a given type (e.g. 91bg-like objects), $N_{tot}$ is the total number of that type, and $N_{false}$ is the number of incorrectly classified objects. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_fom_boundary(fom_type, axis, *args, **kwargs):\n",
    "    \"\"\"Plot the boundaries from an FOM calculation\n",
    "    \n",
    "    Args:\n",
    "        fom_type (str): The type of FOM calculation that was used \n",
    "        axis    (Axis): The matplotlib axis to plot on \n",
    "        *args  (float): The boundaries of the FOM calculation  \n",
    "        **kwargs: Plotting options \n",
    "    \"\"\"\n",
    "    \n",
    "    xlim = axis.get_xlim()\n",
    "    ylim = axis.get_ylim()\n",
    "    if fom_type == 'rectangular':\n",
    "        axis.axhline(args[0], **kwargs)\n",
    "        if 'label' in kwargs:\n",
    "            kwargs.pop('label')\n",
    "\n",
    "        axis.axvline(args[1], **kwargs)\n",
    "        \n",
    "    elif fom_type == 'horizontal':\n",
    "        axis.axvline(args[0], **kwargs)\n",
    "\n",
    "    elif fom_type == 'vertical':\n",
    "        axis.axhline(args[0], **kwargs)\n",
    "\n",
    "    elif fom_type == 'linear':\n",
    "        x = np.array([-1e4, 1e4])\n",
    "        axis.plot(x, args[0] * x + args[1], **kwargs)\n",
    "\n",
    "    elif fom_type == 'diagonal':\n",
    "        x = np.array([-1e4, 1e4])\n",
    "        axis.plot(x, - x + args[0], **kwargs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unknown FOM type {fom_type}')\n",
    "\n",
    "    axis.set_xlim(xlim)\n",
    "    axis.set_ylim(ylim)\n",
    "    axis.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "rectangular_lam = lambda args: 1 - fom.rectangular(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'], \n",
    "    x_cutoff=args[0], \n",
    "    y_cutoff=args[1], \n",
    "    check_type='91bg')\n",
    "\n",
    "rectangular_min = optimize.minimize(rectangular_lam, np.array([0, 0]), method='Powell')\n",
    "x_cutoff, y_cutoff = rectangular_min['x']\n",
    "rectangular_fom = 1 - rectangular_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'rectangular', \n",
    "    static_axis, \n",
    "    x_cutoff, \n",
    "    y_cutoff,\n",
    "    linestyle='--', \n",
    "    color='black', \n",
    "    alpha=.6, \n",
    "    label=f'FOM = {rectangular_fom:.3}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "vertical_lam = lambda args: 1 - fom.vertical(truth=classifications['spec_class'],\n",
    "    y=classifications['y'], \n",
    "    y_cutoff=args[0], \n",
    "    check_type='91bg')\n",
    "\n",
    "vertical_min = optimize.minimize(vertical_lam, np.array([0]), method='Powell')\n",
    "vertical_cutoff = vertical_min['x']\n",
    "vertical_fom = 1 - vertical_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'vertical', \n",
    "    static_axis, \n",
    "    vertical_cutoff, \n",
    "    linestyle='--',\n",
    "    color='black',\n",
    "    alpha=.6, \n",
    "    label=f'FOM = {vertical_fom:.3}')\n",
    "\n",
    "horizontal_lam = lambda args: 1 - fom.horizontal(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    x_cutoff=args[0], \n",
    "    check_type='91bg')\n",
    "\n",
    "horizontal_min = optimize.minimize(horizontal_lam, np.array([0]), method='Powell')\n",
    "horizontal_cutoff = horizontal_min['x']\n",
    "horizontal_fom = 1 - horizontal_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'horizontal', \n",
    "    static_axis, \n",
    "    horizontal_cutoff, \n",
    "    linestyle=':',\n",
    "    color='black',\n",
    "    alpha=.6, \n",
    "    label=f'FOM = {horizontal_fom:.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_fig, static_axis = create_static_figure(classifications)\n",
    "\n",
    "diagonal_lam = lambda args: 1 - fom.diagonal(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'],\n",
    "    b=args[0],\n",
    "    check_type='91bg')\n",
    "\n",
    "diagonal_min = optimize.minimize(diagonal_lam, np.array([0]), method='Powell')\n",
    "diagonal_b = diagonal_min['x']\n",
    "diagonal_fom = 1 - diagonal_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'diagonal', \n",
    "    static_axis, \n",
    "    diagonal_b, \n",
    "    linestyle='--', \n",
    "    color='black', \n",
    "    alpha=.6,\n",
    "    label=f'Diagonal FOM ({diagonal_b:.2}) = {diagonal_fom:.3}')\n",
    "\n",
    "linear_lam = lambda args: 1 - fom.linear(truth=classifications['spec_class'],\n",
    "    x=classifications['x'], \n",
    "    y=classifications['y'],\n",
    "    m=args[0],\n",
    "    b=args[1],\n",
    "    check_type='91bg')\n",
    "\n",
    "linear_min = optimize.minimize(linear_lam, np.array([-5, 0]), method='Powell')\n",
    "linear_m, linear_b = linear_min['x']\n",
    "linear_fom = 1 - linear_min['fun']\n",
    "\n",
    "subplot_fom_boundary(\n",
    "    'diagonal', \n",
    "    static_axis, \n",
    "    linear_m, \n",
    "    linear_b, \n",
    "    linestyle=':', \n",
    "    color='black', \n",
    "    alpha=.6,\n",
    "    label=f'Linear FOM ({linear_m:.2}, {linear_b:.2})= {linear_fom:.4}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a figure of merit optimization, we can bootstrap our data to determine our final classification parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure bootstrap\n",
    "n_iterations = 100\n",
    "n_size = int(len(classifications) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "fom_values = []\n",
    "classification_params = []\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    sample_data = resample(classifications, n_samples=n_size)\n",
    "    result = optimize.minimize(rectangular_lam, [0, 0], method='Powell')\n",
    "\n",
    "    fom_values.append(1 - result.fun)\n",
    "    classification_params.append(result.x)\n",
    "\n",
    "classification_params = np.array(classification_params).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confidence_intervals(alpha, stats):\n",
    "    p = ((1 - alpha) / 2) * 100\n",
    "    lower = max(0, np.percentile(stats, p))\n",
    "\n",
    "    p = (alpha + ((1 - alpha) / 2)) * 100\n",
    "    upper = min(1.0, np.percentile(stats, p))\n",
    "\n",
    "    return lower, upper\n",
    "\n",
    "\n",
    "alpha=0.95\n",
    "confidence = 0.95\n",
    "average_fom = np.average(fom_values)\n",
    "fom_interval = calc_confidence_intervals(confidence, fom_values)\n",
    "\n",
    "print(f'Average FOM: {average_fom}')\n",
    "print(f'{alpha * 100:.1f} confidence interval: [{fom_interval[0] * 100:.1f} '\n",
    "      f', {fom_interval[1] * 100:.1f}]')\n",
    "\n",
    "average_params = np.average(classification_params, axis=1)\n",
    "blue_param_interval = calc_confidence_intervals(confidence, classification_params[0])\n",
    "red_param_interval = calc_confidence_intervals(confidence, classification_params[1])\n",
    "\n",
    "print(f'Average classification params: {average_params}')\n",
    "print(f'{alpha * 100} confidence interval for blue '\n",
    "      f'boundary: [{blue_param_interval[0]:.2f} '\n",
    "      f', {blue_param_interval[1]:.2f}]')\n",
    "\n",
    "print(f'{alpha * 100} confidence interval for red '\n",
    "      f'boundary: [{red_param_interval[0]:.2f} '\n",
    "      f', {red_param_interval[1]:.2f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phot_class] *",
   "language": "python",
   "name": "conda-env-phot_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
